{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "57\n",
      "total 14315\n",
      "14315\n",
      "(1961462, 2)\n",
      "1961462\n",
      "<class 'list'>\n",
      "6584\n",
      "none CHEMBL4303803\n",
      "7209\n"
     ]
    }
   ],
   "source": [
    "### find common based on name between compounds  DB and chembl  and write to csv \n",
    "import pandas as pd\n",
    "dfdb2 =pd.read_csv('data/drugbank_drug.tsv',delimiter='\\t',encoding='utf-8')\n",
    "\n",
    "print(dfdb2.columns[2]) #2=name\n",
    "print(len(dfdb2.columns))\n",
    "\n",
    "listNames_compoundDB=[]\n",
    "listExactMatchNames_compoundDB=[]\n",
    "listChemblNames=[]\n",
    "dictExactMatchNames_compoundDB={}\n",
    "\n",
    "listNames_compoundDB=[x.lower() for x in dfdb2.iloc[:,2]]\n",
    "\n",
    "print(\"total\",len(dfdb2.iloc[:,2]))                    \n",
    "print(len(listNames_compoundDB))\n",
    "\n",
    "#chembl26_prefnames_ids = all name's and id's exported from chembl sql as csv with sql query\n",
    "#SELECT pref_name, chembl_id from chembl_26.molecule_dictionary \n",
    "\n",
    "dfChemblNames =pd.read_csv('data/chembl27_prefnames_ids.csv',delimiter='\\t',encoding='utf-8') #chembl24prefnames.csv\n",
    "print(dfChemblNames.shape)\n",
    "\n",
    "#add to list only contains names\n",
    "listChemblNames= [str(x).lower() for x in dfChemblNames.iloc[:,0]]\n",
    "\n",
    "print(len(listChemblNames))\n",
    "\n",
    "print(type(listChemblNames))\n",
    "\n",
    "count=0\n",
    "for item in listNames_compoundDB:\n",
    "    count=count+1\n",
    "    if item is None or pd.isnull(item) or len(item) == 0:\n",
    "        continue\n",
    "    if item in listChemblNames:\n",
    "        listExactMatchNames_compoundDB.append(item)\n",
    "\n",
    "print(len(listExactMatchNames_compoundDB))\n",
    "\n",
    "\n",
    "\n",
    "#add to dict chembl id as value and name as key\n",
    "listChemblNames= [str(x).lower() for x in dfChemblNames[dfChemblNames.columns[0]]]\n",
    "listChemblIds=[str(x) for x in dfChemblNames[dfChemblNames.columns[1]]]\n",
    "dictChemblNamesIds=dict(zip(listChemblNames,listChemblIds))\n",
    "\n",
    "#consider checking names in drugbank to synonmys in chembl\n",
    "dfChemblSynonyms =pd.read_csv('data/chembl27_synonyms_ids.csv',delimiter='\\t',encoding='utf-8')#chembl24_synonyms\n",
    "listChemblSNames= [str(x).lower() for x in dfChemblSynonyms[dfChemblSynonyms.columns[0]]]\n",
    "listChemblSIds=[str(x) for x in dfChemblSynonyms[dfChemblSynonyms.columns[1]]]\n",
    "dictChemblSIds=dict(zip(listChemblSNames,listChemblSIds))\n",
    "\n",
    "\n",
    "for key, value in dictChemblNamesIds.items() :\n",
    "    print(key, value)\n",
    "    break\n",
    "    \n",
    "\n",
    "        \n",
    "for item in listNames_compoundDB:\n",
    "    if item is None or pd.isnull(item) or len(item) == 0:\n",
    "        continue\n",
    "    if item in dictChemblNamesIds:\n",
    "        dictExactMatchNames_compoundDB[item]= dictChemblNamesIds[item]  \n",
    "    if item in dictChemblSIds:\n",
    "        dictExactMatchNames_compoundDB[item]= dictChemblSIds[item] \n",
    "      \n",
    "       \n",
    "print(len(dictExactMatchNames_compoundDB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lepirudin CHEMBL1201666\n",
      "lepirudin\n"
     ]
    }
   ],
   "source": [
    "for key, value in dictExactMatchNames_compoundDB.items() :\n",
    "    print(key, value)\n",
    "    break\n",
    "print(listExactMatchNames_compoundDB[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n",
      "lepirudin\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(listChemblNames[1801523])\n",
    "print(listNames_compoundDB[0])\n",
    "print(type(listChemblNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "count=0\n",
    "dataArr=dfdb2.values\n",
    "for idx in range(len(dfdb2.values)):\n",
    "    print(\"ss\")\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "#add chembl id also to csv matches file \n",
    "with open(\"data/out/outmatches_names_drugnames_chemblids.tsv\",'w') as outcsv2: \n",
    "    writer2=csv.writer(outcsv2,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')  \n",
    "    with open(\"data/out/outmatches_names_chemblids.tsv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "        for idd in range(len(dfdb2.values)):\n",
    "            dbname=str(dataArr[idd][2]).lower()\n",
    "            if dbname=='':\n",
    "                continue\n",
    "            if dbname in dictExactMatchNames_compoundDB.keys():\n",
    "                for name, idval in dictExactMatchNames_compoundDB.items():   \n",
    "                    if dbname == name:                    \n",
    "                        item=dataArr[idd]  \n",
    "                        chemblid=idval\n",
    "                        writer.writerow([ chemblid] + list(item)[0:55])\n",
    "                        writer2.writerow([chemblid, item[0], item[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_description\n",
      "inchi\n",
      "sequences\n",
      "description\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "dfdb2 =pd.read_csv('data/drugbank_drug.tsv',delimiter='\\t',encoding='utf-8')\n",
    "\n",
    "print(dfdb2.columns[29]) #2=name\n",
    "print(dfdb2.columns[53]) #44=calculated properties\n",
    "print(dfdb2.columns[45]) \n",
    "print(dfdb2.columns[55]) \n",
    "\n",
    "print(len(dfdb2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['drugbank_id', 'alternative_drugbank_ids', 'name', 'cas_number', 'unii',\n",
      "       'atc_codes', 'state', 'groups',\n",
      "       'general_references_links_reference_id_title_url',\n",
      "       'general_references_attachment_reference_id_title_url',\n",
      "       'general_references_textbooks_reference_id_isbn_citation',\n",
      "       'general_references_articles_reference_id_pubmed_citation',\n",
      "       'synthesis_reference', 'indication', 'pharmacodynamics',\n",
      "       'mechanism_of_action', 'toxicity', 'metabolism', 'absorption',\n",
      "       'half_life', 'protein_binding', 'route_of_elimination',\n",
      "       'volume_of_distribution', 'clearance', 'classification_subclass',\n",
      "       'classification_class', 'classification_superclass',\n",
      "       'classification_kingdom', 'classification_direct_parent',\n",
      "       'classification_description', 'synonyms',\n",
      "       'international_brands_name_company', 'mixtures_name_ingredients',\n",
      "       'packagers_name_url', 'manufacturers', 'prices_description_cost_unit',\n",
      "       'affected_organisms', 'dosages_form_route_strength', 'atc_code_levels',\n",
      "       'ahfs_codes', 'pdb_entries', 'fda_label', 'msds',\n",
      "       'patents_number_country_approved_expires_pediatric_extension',\n",
      "       'food_interaction', 'sequences',\n",
      "       'calculated_properties_kind_value_source',\n",
      "       'experimental_properties_kind_value_source', 'external_identifiers',\n",
      "       'external_links_resource_url', 'type',\n",
      "       'classification_alternative_parent', 'classification_substituent',\n",
      "       'inchi', 'inchikey', 'description', 'ChEMBL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dfdb2.columns) #2=name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synonyms\n",
      "57\n",
      "total 14315\n",
      "14315\n",
      "lepirudin recombinant||hirudin variant-1||ith1_hirme\n",
      "(174215, 2)\n",
      "174215\n",
      "<class 'list'>\n",
      "2009\n",
      "bromoenol lactone CHEMBL1256018\n",
      "4319\n"
     ]
    }
   ],
   "source": [
    "### find common based on synonmys  between compounds  DB and chembl  and write to csv \n",
    "dfdb2 =pd.read_csv('data/drugbank_drug.tsv',delimiter='\\t',encoding='utf-8')\n",
    "\n",
    "print(dfdb2.columns[30]) #2=name\n",
    "print(len(dfdb2.columns))\n",
    "\n",
    "listsynonyms_compoundDB=[]\n",
    "listsynonyms_compoundDB_all=[]\n",
    "listExactMatchSynonyms_compoundDB=[]\n",
    "listChemblSynonyms=[]\n",
    "dictExactMatchSynonyms_compoundDB={}\n",
    "\n",
    "\n",
    "listsynonyms_compoundDB=[str(x).lower() for x in dfdb2[dfdb2.columns[30]]]\n",
    "\n",
    "print(\"total\",len(dfdb2[dfdb2.columns[30]]))                    \n",
    "print(len(listsynonyms_compoundDB))\n",
    "print(listsynonyms_compoundDB[0])\n",
    "\n",
    "#chembl26_synonyms_ids = all name's and synonym's exported from chembl sql as csv with sql query\n",
    "'''\n",
    "SELECT a.SYNONYMS, b.chembl_id from \n",
    "chembl_26.molecule_synonyms as a\n",
    "INNER JOIN chembl_26.molecule_dictionary as b\n",
    "ON a.molregno = b.molregno;\n",
    "'''\n",
    "\n",
    "dfChemblSynonyms =pd.read_csv('data/chembl27_synonyms_ids.csv',delimiter='\\t',encoding='utf-8')#chembl24_synonyms\n",
    "print(dfChemblSynonyms.shape)\n",
    "listChemblSynonyms= [str(x).lower() for x in dfChemblSynonyms[dfChemblSynonyms.columns[0]]]\n",
    "\n",
    "print(len(listChemblSynonyms))\n",
    "\n",
    "print(type(listChemblSynonyms))\n",
    "\n",
    "count=0\n",
    "for item in listChemblSynonyms:\n",
    "    if item is None or pd.isnull(item) or len(item) == 0:\n",
    "        continue\n",
    "    count=count+1   \n",
    "    if item in listsynonyms_compoundDB :\n",
    "        listExactMatchSynonyms_compoundDB.append(item)\n",
    "        \n",
    "print(len(listExactMatchSynonyms_compoundDB))\n",
    "\n",
    "#add to dict chembl id as value and synonyms as key\n",
    "listChemblSNames= [str(x).lower() for x in dfChemblSynonyms[dfChemblSynonyms.columns[0]]]\n",
    "listChemblSIds=[str(x) for x in dfChemblSynonyms[dfChemblSynonyms.columns[1]]]\n",
    "dictChemblSIds=dict(zip(listChemblSNames,listChemblSIds))\n",
    "\n",
    "#consider checking drugbank synonyms to names in chembl\n",
    "dfChemblNames =pd.read_csv('data/chembl27_prefnames_ids.csv',delimiter='\\t',encoding='utf-8') #chembl24prefnames.csv\n",
    "listChemblNames= [str(x).lower() for x in dfChemblNames[dfChemblNames.columns[0]]]\n",
    "listChemblIds=[str(x) for x in dfChemblNames[dfChemblNames.columns[1]]]\n",
    "dictChemblNamesIds=dict(zip(listChemblNames,listChemblIds))\n",
    "\n",
    "\n",
    "for key, value in dictChemblSIds.items() :\n",
    "    print(key, value)\n",
    "    break\n",
    "    \n",
    "#db synonmys contains  formate |a||||aa||||bb||||b|\n",
    "for x in listsynonyms_compoundDB:\n",
    "    x=str(x)\n",
    "    if '|' in x:\n",
    "        xall = x.replace('||||','|')\n",
    "        xarr = xall.split(\"|\")\n",
    "        for m in xarr:\n",
    "            if m!= '':\n",
    "                listsynonyms_compoundDB_all.append(m)\n",
    "    else:\n",
    "        if x is None or pd.isnull(x) or len(x) == 0:\n",
    "            m=x\n",
    "            listsynonyms_compoundDB_all.append(m)\n",
    "\n",
    "for item in listsynonyms_compoundDB_all:\n",
    "    if item is None or pd.isnull(item) or len(item) == 0:\n",
    "        continue\n",
    "    if item in dictChemblSIds:\n",
    "        dictExactMatchSynonyms_compoundDB[item]= dictChemblSIds[item] \n",
    "    if item in dictChemblNamesIds:\n",
    "        dictExactMatchSynonyms_compoundDB[item]= dictChemblNamesIds[item] \n",
    "\n",
    "        \n",
    "print(len(dictExactMatchSynonyms_compoundDB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "count=0\n",
    "dataArr=dfdb2.values\n",
    "\n",
    "#add chembl id also to csv synonym matches file \n",
    "with open(\"data/out/outmatches_synonyms_drugnames_chemblids.tsv\",'w') as outcsv2: \n",
    "    writer2=csv.writer(outcsv2,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')  \n",
    "    with open(\"data/out/outmatches_synonyms_chemblids.tsv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "        for idd in range(len(dfdb2.values)):\n",
    "            synonyms=str(dataArr[idd][30]).lower()\n",
    "            if '|' in synonyms:\n",
    "                xall = synonyms.replace('||||','|')\n",
    "                xarr = xall.split(\"|\")              \n",
    "                for arr in xarr:     \n",
    "                    if arr=='':\n",
    "                        continue\n",
    "                    if arr in dictExactMatchSynonyms_compoundDB.keys():\n",
    "                        chemblid=dictExactMatchSynonyms_compoundDB[arr]                               \n",
    "                        item=dataArr[idd]  \n",
    "            else:\n",
    "                arr=synonyms\n",
    "                if arr=='':\n",
    "                    continue\n",
    "                if arr in dictExactMatchSynonyms_compoundDB.keys():\n",
    "                        chemblid=dictExactMatchSynonyms_compoundDB[arr]                               \n",
    "                        item=dataArr[idd]  \n",
    "                        \n",
    "            writer.writerow([ chemblid,item[0],item[1],item[2],item[3],item[4], item[5],item[6],item[7],item[8],item[9],item[10],\n",
    "                            item[11],item[12],item[13],item[14], item[15],item[16],item[17],item[18],item[19],item[20],\n",
    "                             item[21],item[22],item[23],item[24], item[25],item[26],item[27],item[28],item[29],item[30],\n",
    "                            item[31],item[32],item[33],item[34], item[35],item[36],item[37],item[38],item[39],item[40],\n",
    "                           item[41],item[42],item[43],item[44], item[45],item[46],item[47],item[48],item[49],item[50],\n",
    "                               item[51],item[52],item[53],item[54],item[55],item[56]])\n",
    "            writer2.writerow([chemblid, item[0], item[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inchikey\n"
     ]
    }
   ],
   "source": [
    "### find common based on inchikey between compounds DB and chembl  and write to csv \n",
    "import pandas as pd\n",
    "dfdb2 =pd.read_csv('data/drugbank_drug.tsv',delimiter='\\t',encoding='utf-8')\n",
    "\n",
    "\n",
    "print(dfdb2.columns[54]) \n",
    "listInchiKey_CompoundDB=[]\n",
    "listInchiKeyOnly_CompoundDB=[]\n",
    "listInchiKey_CompoundDB.append(dfdb2[dfdb2.columns[53]])\n",
    "count=0\n",
    "\n",
    "for item in dfdb2[dfdb2.columns[54]]:\n",
    "    count = count+1\n",
    "    item=str(item)\n",
    "    listInchiKeyOnly_CompoundDB.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inchikey\n"
     ]
    }
   ],
   "source": [
    "print(dfdb2.columns[54]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14315\n"
     ]
    }
   ],
   "source": [
    "print(len(listInchiKeyOnly_CompoundDB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(listInchiKeyOnly_CompoundDB[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14315\n",
      "1941411\n",
      "<class 'list'>\n",
      "7926\n",
      "AAAAEENPAALFRN-UHFFFAOYSA-N CHEMBL492934\n"
     ]
    }
   ],
   "source": [
    "print(len(listInchiKeyOnly_CompoundDB))\n",
    "dfChembl =pd.read_csv('data/chembl27inchikey.csv',delimiter=',',encoding='utf-8') #.chembl26inchikey\n",
    "listChemblInchiKey=dfChembl.values.tolist()\n",
    "print(len(listChemblInchiKey))\n",
    "print(type(listChemblInchiKey))\n",
    "#exact matches inchikey against compound db\n",
    "listExactMatch_CompoundDB=[]\n",
    "dictExactMatchInchi_compoundDB={}\n",
    "\n",
    "for item in listChemblInchiKey: \n",
    "    if item[0] is None or pd.isnull(item[0]) or len(item[0]) == 0:\n",
    "        continue\n",
    "    if item[0] in listInchiKeyOnly_CompoundDB:        \n",
    "        listExactMatch_CompoundDB.append(item[0])\n",
    "\n",
    "print(len(listExactMatch_CompoundDB))\n",
    "\n",
    "#chembl26inchikey_chemblids = all inchi keys exported from chembl sql as csv with sql query\n",
    "'''\n",
    "SELECT a.standard_inchi_key, b.chembl_id from \n",
    "chembl_26.compound_structures as a\n",
    "INNER JOIN chembl_26.molecule_dictionary as b\n",
    "ON a.molregno = b.molregno;\n",
    "'''\n",
    "\n",
    "dfChemblInchi =pd.read_csv('data/chembl27inchikey_chemblids.csv',delimiter=',',encoding='utf-8') #.chembl26inchikey\n",
    "#add to dict chembl id as value and synonyms as key\n",
    "listChemblInchi= [str(x) for x in dfChemblInchi[dfChemblInchi.columns[0]]]\n",
    "listChemblIds=[str(x) for x in dfChemblInchi[dfChemblInchi.columns[1]]]\n",
    "\n",
    "\n",
    "dictChemblInchiIds=dict(zip(listChemblInchi,listChemblIds))\n",
    "\n",
    "for key, value in dictChemblInchiIds.items() :\n",
    "    print(key, value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7926\n"
     ]
    }
   ],
   "source": [
    "for item in listInchiKeyOnly_CompoundDB:\n",
    "    if item is None or len(item) == 0:\n",
    "        continue\n",
    "    if item in dictChemblInchiIds:\n",
    "        dictExactMatchInchi_compoundDB[item]= dictChemblInchiIds[item] \n",
    "       \n",
    "print(len(dictExactMatchInchi_compoundDB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "count=0\n",
    "dataArr=dfdb2.values\n",
    "for idx in range(len(dfdb2.values)):\n",
    "    print(\"ss\")\n",
    "    break\n",
    "          \n",
    "#add chembl id also to csv synonym matches file \n",
    "with open(\"data/out/outmatches_inchikey_drugnames_chemblids.tsv\",'w') as outcsv2: \n",
    "    writer2=csv.writer(outcsv2,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')  \n",
    "    with open(\"data/out/outmatches_inchikey_chemblids.tsv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "        for idd in range(len(dfdb2.values)):\n",
    "            dbname=dataArr[idd][54]\n",
    "            if dbname in dictExactMatchInchi_compoundDB.keys():\n",
    "                for name, idval in dictExactMatchInchi_compoundDB.items():   \n",
    "                    if dbname == name:                    \n",
    "                        item=dataArr[idd]  \n",
    "                        chemblid=idval\n",
    "                        writer.writerow([ chemblid,item[0],item[1],item[2],item[3],item[4], item[5],item[6],item[7],item[8],item[9],item[10],\n",
    "                            item[11],item[12],item[13],item[14], item[15],item[16],item[17],item[18],item[19],item[20],\n",
    "                             item[21],item[22],item[23],item[24], item[25],item[26],item[27],item[28],item[29],item[30],\n",
    "                            item[31],item[32],item[33],item[34], item[35],item[36],item[37],item[38],item[39],item[40],\n",
    "                           item[41],item[42],item[43],item[44], item[45],item[46],item[47],item[48],item[49],item[50],\n",
    "                               item[51],item[52],item[53],item[54],item[55],item[56]])\n",
    "                        writer2.writerow([chemblid, item[0], item[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: | \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::imageio==2.9.0=py_0\n",
      "  - defaults/noarch::dask==2021.3.0=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::bkcharts==0.2=py37_0\n",
      "  - defaults/linux-64::numpy==1.19.2=py37h54aff64_0\n",
      "  - defaults/linux-64::scikit-image==0.14.2=py37he6710b0_0\n",
      "  - defaults/linux-64::_anaconda_depends==2019.10=py37_0\n",
      "  - defaults/linux-64::anaconda-client==1.7.2=py37_0\n",
      "  - defaults/linux-64::astropy==3.1.2=py37h7b6447c_0\n",
      "  - defaults/noarch::requests==2.25.1=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::patsy==0.5.1=py37_0\n",
      "  - defaults/linux-64::bokeh==2.3.0=py37h06a4308_0\n",
      "  - conda-forge/linux-64::_openmp_mutex==4.5=1_gnu\n",
      "  - defaults/noarch::numpydoc==1.1.0=pyhd3eb1b0_1\n",
      "  - defaults/linux-64::scipy==1.6.1=py37h91f5cce_0\n",
      "  - defaults/linux-64::mkl_random==1.1.1=py37h0573a6f_0\n",
      "  - defaults/linux-64::bottleneck==1.3.2=py37heb32a55_1\n",
      "  - defaults/linux-64::h5py==2.10.0=py37h7918eee_0\n",
      "  - defaults/linux-64::numba==0.43.1=py37h962f231_0\n",
      "  - defaults/linux-64::anaconda-navigator==1.9.7=py37_0\n",
      "  - conda-forge/linux-64::libgomp==9.3.0=h5dbcf3e_17\n",
      "  - defaults/linux-64::spyder==3.3.3=py37_0\n",
      "  - defaults/linux-64::statsmodels==0.12.1=py37h27cfd23_0\n",
      "  - defaults/linux-64::pytest-arraydiff==0.3=py37h39e3cac_0\n",
      "  - defaults/linux-64::pywavelets==1.1.1=py37h7b6447c_2\n",
      "  - defaults/linux-64::pytest-astropy==0.5.0=py37_0\n",
      "  - defaults/linux-64::anaconda-project==0.8.2=py37_0\n",
      "  - defaults/linux-64::anaconda==custom=py37_1\n",
      "  - defaults/linux-64::matplotlib==3.0.3=py37h5429711_0\n",
      "  - defaults/linux-64::seaborn==0.9.0=py37_0\n",
      "  - defaults/linux-64::numexpr==2.7.3=py37hb2eb853_0\n",
      "  - defaults/linux-64::pytables==3.6.1=py37h71ec239_0\n",
      "  - defaults/linux-64::conda==4.9.2=py37h06a4308_0\n",
      "  - defaults/linux-64::conda-build==3.17.8=py37_0\n",
      "  - defaults/noarch::sphinx==3.5.3=pyhd3eb1b0_0\n",
      "  - defaults/linux-64::mkl_fft==1.3.0=py37h54f3939_0\n",
      "  - defaults/linux-64::pytest-doctestplus==0.3.0=py37_0\n",
      "| ^C\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated_properties_kind_value_source\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [00:46:44] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "RDKit ERROR: [00:46:44] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "RDKit ERROR: [00:46:44] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "RDKit ERROR: [00:46:45] SMILES Parse Error: syntax error while parsing: OS(O)(O)C1=CC=C(C=C1)C-1=C2\\C=CC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC=C(C=C1)S(O)(O)O)C1=CC=C(C=C1)S([O-])([O-])[O-])\\C1=CC=C(C=C1)S(O)(O)[O-]\n",
      "RDKit ERROR: [00:46:45] SMILES Parse Error: Failed parsing SMILES 'OS(O)(O)C1=CC=C(C=C1)C-1=C2\\C=CC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC=C(C=C1)S(O)(O)O)C1=CC=C(C=C1)S([O-])([O-])[O-])\\C1=CC=C(C=C1)S(O)(O)[O-]' for input: 'OS(O)(O)C1=CC=C(C=C1)C-1=C2\\C=CC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC=C(C=C1)S(O)(O)O)C1=CC=C(C=C1)S([O-])([O-])[O-])\\C1=CC=C(C=C1)S(O)(O)[O-]'\n",
      "RDKit ERROR: [00:46:45] Explicit valence for atom # 14 N, 5, is greater than permitted\n",
      "RDKit ERROR: [00:46:45] Explicit valence for atom # 19 O, 3, is greater than permitted\n",
      "RDKit ERROR: [00:46:45] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "RDKit ERROR: [00:46:45] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "RDKit ERROR: [00:46:46] Explicit valence for atom # 0 O, 3, is greater than permitted\n",
      "RDKit ERROR: [00:46:46] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "RDKit ERROR: [00:46:46] Explicit valence for atom # 4 F, 2, is greater than permitted\n",
      "RDKit ERROR: [00:46:46] Explicit valence for atom # 4 F, 2, is greater than permitted\n",
      "RDKit ERROR: [00:46:47] Explicit valence for atom # 13 Be, 3, is greater than permitted\n",
      "RDKit ERROR: [00:46:48] Explicit valence for atom # 84 N, 4, is greater than permitted\n",
      "RDKit ERROR: [00:46:48] SMILES Parse Error: syntax error while parsing: OC1=CC=CC(=C1)C-1=C2\\CCC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\\C1=CC(O)=CC=C1\n",
      "RDKit ERROR: [00:46:48] SMILES Parse Error: Failed parsing SMILES 'OC1=CC=CC(=C1)C-1=C2\\CCC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\\C1=CC(O)=CC=C1' for input: 'OC1=CC=CC(=C1)C-1=C2\\CCC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\\C1=CC(O)=CC=C1'\n",
      "RDKit ERROR: [00:46:49] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "RDKit ERROR: [00:46:49] Explicit valence for atom # 5 K, 2, is greater than permitted\n",
      "RDKit WARNING: [00:46:50] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [00:46:50] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [00:46:50] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit ERROR: [00:46:50] Explicit valence for atom # 14 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listSMILES_CompoundDBOnly_CompoundDB 11290\n",
      "1941411\n",
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [01:00:20] SMILES Parse Error: syntax error while parsing: None\n",
      "RDKit ERROR: [01:00:20] SMILES Parse Error: Failed parsing SMILES 'None' for input: 'None'\n",
      "RDKit WARNING: [01:11:28] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [01:16:31] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [01:16:45] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [01:16:59] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [01:25:58] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [01:25:58] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [01:25:58] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [01:37:02] SMILES Parse Error: syntax error while parsing: None\n",
      "RDKit ERROR: [01:37:02] SMILES Parse Error: Failed parsing SMILES 'None' for input: 'None'\n",
      "RDKit WARNING: [01:43:00] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [01:46:02] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [01:46:12] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [01:46:22] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [01:51:47] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [01:51:47] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [01:51:47] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cc1cc(-n2ncc(=O)[nH]c2=O)ccc1C(=O)c1ccccc1Cl CHEMBL6329\n"
     ]
    }
   ],
   "source": [
    "### find common based on smiles between compounds DB and chembl  and write to csv \n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "dfdb2 =pd.read_csv('data/drugbank_drug.tsv',delimiter='\\t',encoding='utf-8')\n",
    "print(dfdb2.columns[46]) #44=calculated properties\n",
    "listSMILES_CompoundDB=[]\n",
    "listSMILES_CompoundDBOnly_CompoundDB=[]\n",
    "listSMILES_CompoundDB.append(dfdb2[dfdb2.columns[46]])\n",
    "count=0\n",
    "listsmiConvertErrorDB=[]\n",
    "listsmiConvertErrorChembl=[]\n",
    "\n",
    "\n",
    "for item in dfdb2[dfdb2.columns[46]]:\n",
    "    count = count+1  \n",
    "    #print(\"item\",item)\n",
    "    if str(item) != 'nan':\n",
    "        #print(\"not nan\")\n",
    "        #if item is None or pd.isnull(item) or len(item) == 0 :            \n",
    "        item=str(item)\n",
    "        #print(\"str item\", item)\n",
    "        if item is None or pd.isnull(item) or len(item) == 0:\n",
    "            continue\n",
    "        arr = item.split('||')\n",
    "        #print(\"arr \", arr)\n",
    "\n",
    "        arr2=[]\n",
    "        for item in arr:\n",
    "            if 'SMILES' in item:\n",
    "                arr2.append(item)\n",
    "                for item in arr2:\n",
    "                    val = item.split('::')                    \n",
    "                    #print(\"val\",val[1])\n",
    "                    #print(\"mol2smi\",Chem.MolToSmiles(Chem.MolFromSmiles(val[1]), True))\n",
    "                    try:                        \n",
    "                        listSMILES_CompoundDBOnly_CompoundDB.append(Chem.MolToSmiles(Chem.MolFromSmiles(val[1]), True)) \n",
    "                    except:\n",
    "                        listsmiConvertErrorDB.append(val[1])\n",
    "   \n",
    "                    \n",
    "print(\"listSMILES_CompoundDBOnly_CompoundDB\", len(listSMILES_CompoundDBOnly_CompoundDB))  \n",
    "\n",
    "#chembl26smiles = all smiles exported from chembl sql as csv with sql query\n",
    "'''\n",
    "chembl26smiles contains only smiles,chembl26smiles_chemblids contains smiles, ids\n",
    "SELECT a.canonical_smiles, b.chembl_id from \n",
    "chembl_26.compound_structures as a\n",
    "INNER JOIN chembl_26.molecule_dictionary as b\n",
    "ON a.molregno = b.molregno;\n",
    "'''\n",
    "\n",
    "dfChembl =pd.read_csv('data/chembl27smiles.csv',delimiter='\\t',encoding='utf-8')\n",
    "listChemblsmiles=dfChembl.values.tolist()\n",
    "print(len(listChemblsmiles))\n",
    "print(type(listChemblsmiles))\n",
    "listExactMatchsmiles_CompoundDB=[]\n",
    "\n",
    "dictExactMatchSmi_compoundDB={}\n",
    "for item in listChemblsmiles:  \n",
    "    if item is None or pd.isnull(item) or len(item) == 0:\n",
    "        continue\n",
    "    #canonical smiles\n",
    "    try:        \n",
    "        canonical_smiles=Chem.MolToSmiles(Chem.MolFromSmiles(item[0]), True)\n",
    "        if canonical_smiles in listSMILES_CompoundDBOnly_CompoundDB:        \n",
    "            listExactMatchsmiles_CompoundDB.append(item[0])\n",
    "    except :\n",
    "        listsmiConvertErrorChembl.append(item[0])\n",
    "\n",
    "print(len(listExactMatchsmiles_CompoundDB))\n",
    "\n",
    "\n",
    "dfChemblSMI =pd.read_csv('data/chembl27smiles_chemblids.csv',delimiter='\\t',encoding='utf-8') #.chembl24smiles\n",
    "#add to dict chembl id as value and synonyms as key\n",
    "#listChemblSMI= [Chem.MolToSmiles(Chem.MolFromSmiles(str(x)), True)for x in dfChemblSMI[dfChemblSMI.columns[0]]]                \n",
    "#listChemblIds=[str(x) for x in dfChemblSMI[dfChemblSMI.columns[1]]]\n",
    "listsmiConvertError2=[]\n",
    "listChemblSMI=[]\n",
    "listChemblIds=[]\n",
    "\n",
    "for index,x in enumerate(dfChemblSMI[dfChemblSMI.columns[0]]):\n",
    "    try:\n",
    "        chemSMI= Chem.MolToSmiles(Chem.MolFromSmiles(str(x)), True)\n",
    "        listChemblSMI.append(chemSMI)\n",
    "        listChemblIds.append(str(dfChemblSMI[dfChemblSMI.columns[1]][index]))\n",
    "        \n",
    "    except:\n",
    "       # listsmiConvertErrorChembl.append(str(x)) \n",
    "        listsmiConvertError2.append(str(x))                     \n",
    "\n",
    "dictChemblSmiIds=dict(zip(listChemblSMI,listChemblIds))\n",
    "\n",
    "for key, value in dictChemblSmiIds.items() :\n",
    "    print(key, value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7617\n"
     ]
    }
   ],
   "source": [
    "for item in listSMILES_CompoundDBOnly_CompoundDB: \n",
    "    if item is None or pd.isnull(item) or len(item) == 0:\n",
    "        continue\n",
    "    if item in dictChemblSmiIds:\n",
    "        dictExactMatchSmi_compoundDB[item]= dictChemblSmiIds[item] \n",
    "             \n",
    "print(len(dictExactMatchSmi_compoundDB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC[C@H](C)[C@H](NC(=O)[C@H](CCC(=O)O)NC(=O)[C@H](CCC(=O)O)NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@H](CC(=O)O)NC(=O)CNC(=O)[C@H](CC(N)=O)NC(=O)CNC(=O)CNC(=O)CNC(=O)CNC(=O)[C@@H]1CCCN1C(=O)[C@H](CCCNC(=N)N)NC(=O)[C@@H]1CCCN1C(=O)[C@H](N)Cc1ccccc1)C(=O)N1CCC[C@H]1C(=O)N[C@@H](CCC(=O)O)C(=O)N[C@@H](CCC(=O)O)C(=O)N[C@@H](Cc1ccc(O)cc1)C(=O)N[C@@H](CC(C)C)C(=O)O CHEMBL2103749\n"
     ]
    }
   ],
   "source": [
    "for key, value in dictExactMatchSmi_compoundDB.items() :\n",
    "    print(key, value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [01:53:47] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "RDKit ERROR: [01:53:47] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "RDKit ERROR: [01:53:49] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "RDKit ERROR: [01:53:53] SMILES Parse Error: syntax error while parsing: OS(O)(O)C1=CC=C(C=C1)C-1=C2\\C=CC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC=C(C=C1)S(O)(O)O)C1=CC=C(C=C1)S([O-])([O-])[O-])\\C1=CC=C(C=C1)S(O)(O)[O-]\n",
      "RDKit ERROR: [01:53:53] SMILES Parse Error: Failed parsing SMILES 'OS(O)(O)C1=CC=C(C=C1)C-1=C2\\C=CC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC=C(C=C1)S(O)(O)O)C1=CC=C(C=C1)S([O-])([O-])[O-])\\C1=CC=C(C=C1)S(O)(O)[O-]' for input: 'OS(O)(O)C1=CC=C(C=C1)C-1=C2\\C=CC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC=C(C=C1)S(O)(O)O)C1=CC=C(C=C1)S([O-])([O-])[O-])\\C1=CC=C(C=C1)S(O)(O)[O-]'\n",
      "RDKit ERROR: [01:53:54] Explicit valence for atom # 14 N, 5, is greater than permitted\n",
      "RDKit ERROR: [01:53:55] Explicit valence for atom # 19 O, 3, is greater than permitted\n",
      "RDKit ERROR: [01:53:57] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "RDKit ERROR: [01:53:58] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "RDKit ERROR: [01:53:58] Explicit valence for atom # 0 O, 3, is greater than permitted\n",
      "RDKit ERROR: [01:53:58] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "RDKit ERROR: [01:53:59] Explicit valence for atom # 4 F, 2, is greater than permitted\n",
      "RDKit ERROR: [01:53:59] Explicit valence for atom # 4 F, 2, is greater than permitted\n",
      "RDKit ERROR: [01:54:08] Explicit valence for atom # 13 Be, 3, is greater than permitted\n",
      "RDKit ERROR: [01:54:11] Explicit valence for atom # 84 N, 4, is greater than permitted\n",
      "RDKit ERROR: [01:54:13] SMILES Parse Error: syntax error while parsing: OC1=CC=CC(=C1)C-1=C2\\CCC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\\C1=CC(O)=CC=C1\n",
      "RDKit ERROR: [01:54:13] SMILES Parse Error: Failed parsing SMILES 'OC1=CC=CC(=C1)C-1=C2\\CCC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\\C1=CC(O)=CC=C1' for input: 'OC1=CC=CC(=C1)C-1=C2\\CCC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\\C1=CC(O)=CC=C1'\n",
      "RDKit ERROR: [01:54:19] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "RDKit ERROR: [01:54:23] Explicit valence for atom # 5 K, 2, is greater than permitted\n",
      "RDKit WARNING: [01:54:25] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [01:54:25] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [01:54:26] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit ERROR: [01:54:27] Explicit valence for atom # 14 N, 4, is greater than permitted\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "count=0\n",
    "dataArr=dfdb2.values\n",
    "\n",
    "\n",
    "i=0\n",
    "#add chembl id also to csv smiles matches file \n",
    "with open(\"data/out/outmatches_smiles_drugnames_chemblids.tsv\",'w') as outcsv2: \n",
    "    writer2=csv.writer(outcsv2,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')  \n",
    "    with open(\"data/out/outmatches_smiles_chemblids.tsv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "        \n",
    "        for idd in range(len(dfdb2.values)):\n",
    "            i=i+1\n",
    "            listIm=[]\n",
    "            item_ = dataArr[idd][46]   \n",
    "            #print(\"item_\",item_)\n",
    "            #if str(item_) != 'nan': \n",
    "            #if item is None or pd.isnull(item) or len(item) == 0:\n",
    "                #continue\n",
    "            if item_ != 'nan':\n",
    "                item_=str(item_)\n",
    "                arr = item_.split('||')\n",
    "                arr2=[]\n",
    "                #print(\"item\",item)\n",
    "                for item in arr:\n",
    "                    if 'SMILES' in item:\n",
    "                        arr2.append(item)\n",
    "                        for item in arr2:\n",
    "                            val = item.split('::')\n",
    "                            try:\n",
    "                                sm=Chem.MolToSmiles(Chem.MolFromSmiles(val[1]), True)\n",
    "                                listIm.append(sm) \n",
    "                            except:\n",
    "                                smi='error'\n",
    "            #print(\"listIm\",listIm)       \n",
    "            if listIm:\n",
    "                for objItem in listIm:\n",
    "                    #if listIm[0] in dictExactMatchSmi_compoundDB.keys():\n",
    "                    if objItem in dictExactMatchSmi_compoundDB.keys():                     \n",
    "                        #print(\"in-----\")\n",
    "                        for smi, idval in dictExactMatchSmi_compoundDB.items():   \n",
    "                            if smi == objItem:                    \n",
    "                                item=dataArr[idd]  \n",
    "                                chemblid=idval\n",
    "                                #print(\"added----\")\n",
    "                                writer.writerow([ chemblid,item[0],item[1],item[2],item[3],item[4], item[5],item[6],item[7],item[8],item[9],item[10],\n",
    "                                item[11],item[12],item[13],item[14], item[15],item[16],item[17],item[18],item[19],item[20],\n",
    "                                 item[21],item[22],item[23],item[24], item[25],item[26],item[27],item[28],item[29],item[30],\n",
    "                                item[31],item[32],item[33],item[34], item[35],item[36],item[37],item[38],item[39],item[40],\n",
    "                               item[41],item[42],item[43],item[44], item[45],item[46],item[47],item[48],item[49],item[50],\n",
    "                               item[51],item[52],item[53],item[54]])\n",
    "                                writer2.writerow([chemblid, item[0], item[2]])   \n",
    "                        break\n",
    "            \n",
    "                #if i==10:\n",
    "                    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChEMBL\n",
      "len 7941\n",
      "7941\n",
      "3687712\n",
      "<class 'list'>\n",
      "7941\n"
     ]
    }
   ],
   "source": [
    "### find common based on chembl id  between compounds DB and chembl  and write to csv \n",
    "import pandas as pd\n",
    "dfdb2 =pd.read_csv('data/drugbank_drug.tsv',delimiter='\\t',encoding='utf-8')\n",
    "\n",
    "\n",
    "print(dfdb2.columns[56]) #54=chembl id \n",
    "listChemblID_CompoundDB=[]\n",
    "listChemblIDOnly_CompoundDB=[]\n",
    "\n",
    "\n",
    "count=0\n",
    "\n",
    "for item in dfdb2[dfdb2.columns[56]]:\n",
    "    if not (item is None or pd.isnull(item) or len(item) == 0):\n",
    "        item=str(item)\n",
    "        listChemblIDOnly_CompoundDB.append(item) \n",
    "            \n",
    "print(\"len\",len(listChemblIDOnly_CompoundDB))\n",
    "print(len(listChemblIDOnly_CompoundDB))\n",
    "\n",
    "#chembl26smiles_chemblids.csv contains all chembl_id's exported from chembl_id_lookup table as csv from sql\n",
    "\n",
    "dfChemblids =pd.read_csv('data/chembl27_chemblids.csv',delimiter='\\t',encoding='utf-8')\n",
    "listChemblids=dfChemblids.values.tolist()\n",
    "print(len(listChemblids))\n",
    "print(type(listChemblids))\n",
    "#exact matches inchikey against compound db\n",
    "listExactMatchChemblid_CompoundDB=[]\n",
    "for item in listChemblids: \n",
    "    if item[0] is None or pd.isnull(item[0]) or len(item[0]) == 0:\n",
    "        continue\n",
    "    if item[0] in listChemblIDOnly_CompoundDB:        \n",
    "        listExactMatchChemblid_CompoundDB.append(item[0])\n",
    "\n",
    "print(len(listExactMatchChemblid_CompoundDB))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "count=0\n",
    "dataArr=dfdb2.values\n",
    "for idx in range(len(dfdb2.values)):\n",
    "    print(\"ss\")\n",
    "    break\n",
    "\n",
    "            \n",
    "with open(\"data/out/outmatches_chemblid.tsv\",'w') as outcsv: \n",
    "    writer=csv.writer(outcsv,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "    for idd in range(len(dfdb2.values)):\n",
    "        if dataArr[idd][56] in listExactMatchChemblid_CompoundDB:\n",
    "            item=dataArr[idd]\n",
    "            \n",
    "            writer.writerow([item[0],item[1],item[2],item[3],item[4], item[5],item[6],item[7],item[8],item[9],item[10],\n",
    "                            item[11],item[12],item[13],item[14], item[15],item[16],item[17],item[18],item[19],item[20],\n",
    "                            item[21],item[22],item[23],item[24], item[25],item[26],item[27],item[28],item[29],item[30],\n",
    "                            item[31],item[32],item[33],item[34], item[35],item[36],item[37],item[38],item[39],item[40],\n",
    "                           item[41],item[42],item[43],item[44], item[45],item[46],item[47],item[48],item[49],item[50],\n",
    "                               item[51],item[52],item[53],item[54]])\n",
    "            \n",
    "\n",
    "with open(\"data/out/outmatches_chemblid_drugnames.tsv\",'w') as outcsv: \n",
    "    writer=csv.writer(outcsv,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "    for idd in range(len(dfdb2.values)):\n",
    "        if dataArr[idd][56] in listExactMatchChemblid_CompoundDB:\n",
    "            item=dataArr[idd]\n",
    "            writer.writerow([item[56], item[0],item[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHEMBL1201666' 'DB00001' 'Lepirudin']\n",
      "45008\n",
      "45008\n",
      "45008\n"
     ]
    }
   ],
   "source": [
    "#repeat write complete matches with chembl id to write to non matches list + later use for partial match findings\n",
    "listCompoundDBMatchedNames=[]\n",
    "listCompoundDBMatchedIDs=[]\n",
    "listChemblMatchedIDs=[]\n",
    "\n",
    "\n",
    "dfid =pd.read_csv('data/out/outmatches_chemblid_drugnames.tsv', header=None, delimiter=\"\\t\", encoding='utf-8')\n",
    "listid=dfid.values\n",
    "\n",
    "for item in listid:\n",
    "    listChemblMatchedIDs.append(item[0])\n",
    "    listCompoundDBMatchedIDs.append(item[1])\n",
    "    listCompoundDBMatchedNames.append(item[2])\n",
    "    \n",
    "dfid1 =pd.read_csv('data/out/outmatches_names_drugnames_chemblids.tsv', header=None, delimiter=\"\\t\", encoding='utf-8')\n",
    "listid1=dfid1.values\n",
    "print(listid1[0])\n",
    "for item1 in listid1: \n",
    "    listChemblMatchedIDs.append(item1[0])\n",
    "    listCompoundDBMatchedIDs.append(item1[1])\n",
    "    listCompoundDBMatchedNames.append(item1[2])\n",
    "    \n",
    "dfid2 =pd.read_csv('data/out/outmatches_inchikey_drugnames_chemblids.tsv',header=None,  delimiter=\"\\t\", encoding='utf-8')\n",
    "listid2=dfid2.values\n",
    "\n",
    "for item2 in listid2:\n",
    "    listChemblMatchedIDs.append(item2[0])\n",
    "    listCompoundDBMatchedIDs.append(item2[1])\n",
    "    listCompoundDBMatchedNames.append(item2[2])\n",
    "         \n",
    "dfid3 =pd.read_csv('data/out/outmatches_smiles_drugnames_chemblids.tsv',header=None,  delimiter=\"\\t\", encoding='utf-8')\n",
    "listid3=dfid3.values\n",
    "\n",
    "for item3 in listid3:\n",
    "    listChemblMatchedIDs.append(item3[0])    \n",
    "    listCompoundDBMatchedIDs.append(item3[1])\n",
    "    listCompoundDBMatchedNames.append(item3[2])\n",
    "            \n",
    "#outmatches_synonyms\n",
    "dfid4 =pd.read_csv('data/out/outmatches_synonyms_drugnames_chemblids.tsv',header=None,  delimiter=\"\\t\", encoding='utf-8')\n",
    "listid4=dfid4.values\n",
    "\n",
    "for item4 in listid4:\n",
    "    listChemblMatchedIDs.append(item4[0])    \n",
    "    listCompoundDBMatchedIDs.append(item4[1])\n",
    "    listCompoundDBMatchedNames.append(item4[2])  \n",
    "        \n",
    "print(len(listChemblMatchedIDs))\n",
    "\n",
    "print(len(listCompoundDBMatchedNames))\n",
    "\n",
    "print(len(listCompoundDBMatchedNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss\n",
      "match id 9650\n",
      "match name 0\n",
      "no match 4665\n"
     ]
    }
   ],
   "source": [
    "#write non matches to csv (compared against list of exact matches of name, smiles, inchi,, syonyms, id)\n",
    "\n",
    "import csv\n",
    "\n",
    "count=0\n",
    "dataArr=dfdb2.values\n",
    "for idx in range(len(dfdb2.values)):\n",
    "    print(\"ss\")\n",
    "    break\n",
    "\n",
    "countM=0\n",
    "countN=0\n",
    "\n",
    "\n",
    "with open(\"data/out/exact_outnonmatches_dbid_dbnames.tsv\",'w') as outcsv2:  \n",
    "    writer2=csv.writer(outcsv2,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "\n",
    "    with open(\"data/out/exact_outnonmatches_allfields.tsv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "        for idd in range(len(dfdb2.values)):            \n",
    "            if dataArr[idd][0] in listCompoundDBMatchedIDs :\n",
    "                countM =countM+1\n",
    "            elif dataArr[idd][2] in listCompoundDBMatchedNames:                 \n",
    "                countN =countN+1\n",
    "            else:    \n",
    "                count=count+1\n",
    "                item=dataArr[idd] \n",
    "                writer.writerow([item[0],item[1],item[2],item[3],item[4], item[5],item[6],item[7],item[8],item[9],item[10],\n",
    "                                  item[11],item[12],item[13],item[14], item[15],item[16],item[17],item[18],item[19],item[20],\n",
    "                            item[21],item[22],item[23],item[24], item[25],item[26],item[27],item[28],item[29],item[30],\n",
    "                            item[31],item[32],item[33],item[34], item[35],item[36],item[37],item[38],item[39],item[40],\n",
    "                           item[41],item[42],item[43],item[44], item[45],item[46],item[47],item[48],item[49],item[50],\n",
    "                               item[51],item[52],item[53],item[54],item[55], item[56]])\n",
    "                writer2.writerow([item[0],item[2]])\n",
    "          \n",
    "                     \n",
    "                     \n",
    "                \n",
    "print(\"match id\",countM) \n",
    "                \n",
    "print(\"match name\",countN)  \n",
    "                \n",
    "print(\"no match\",count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9650\n"
     ]
    }
   ],
   "source": [
    "#data fusion part - find only unique matches from all the individual matches (chembl id, name, synonym, inchi, smiles)\n",
    "dictDBID_ChemblID={}\n",
    "\n",
    "df_id =pd.read_csv('data/out/outmatches_chemblid_drugnames.tsv', header=None, delimiter=\"\\t\", encoding='utf-8')\n",
    "listids=df_id.values\n",
    "\n",
    "for item in listids:\n",
    "    dictDBID_ChemblID[item[1]]=item[0]   \n",
    "\n",
    "    \n",
    "df_name =pd.read_csv('data/out/outmatches_names_drugnames_chemblids.tsv', header=None, delimiter=\"\\t\", encoding='utf-8')\n",
    "listnames=df_name.values\n",
    "for item1 in listnames: \n",
    "    dbid=item1[1]\n",
    "    if dbid not in dictDBID_ChemblID.keys():\n",
    "        dictDBID_ChemblID[item1[1]]=item1[0]   \n",
    "\n",
    "df_inchiK =pd.read_csv('data/out/outmatches_inchikey_drugnames_chemblids.tsv', header=None, delimiter=\"\\t\", encoding='utf-8')\n",
    "listInchiK=df_inchiK.values\n",
    "for item2 in listInchiK: \n",
    "    dbid=item2[1]\n",
    "    if dbid not in dictDBID_ChemblID.keys():\n",
    "        dictDBID_ChemblID[item2[1]]=item2[0]      \n",
    "    \n",
    "         \n",
    "df_smi =pd.read_csv('data/out/outmatches_smiles_drugnames_chemblids.tsv',header=None,  delimiter=\"\\t\", encoding='utf-8')\n",
    "listSMI=df_smi.values\n",
    "\n",
    "for item3 in listSMI:\n",
    "    dbid=item3[1]\n",
    "    if dbid not in dictDBID_ChemblID.keys():\n",
    "        dictDBID_ChemblID[item3[1]]=item3[0]     \n",
    "            \n",
    "#outmatches_synonyms\n",
    "df_synonyms =pd.read_csv('data/out/outmatches_synonyms_drugnames_chemblids.tsv',header=None,  delimiter=\"\\t\", encoding='utf-8')\n",
    "listSynonyms=df_synonyms.values\n",
    "for item4 in listSynonyms:\n",
    "    dbid=item4[1]\n",
    "    if dbid not in dictDBID_ChemblID.keys():\n",
    "        dictDBID_ChemblID[item4[1]]=item4[0] \n",
    "\n",
    "\n",
    "print(len(dictDBID_ChemblID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14315\n",
      "ss\n",
      "count= 9650\n"
     ]
    }
   ],
   "source": [
    "#data fusion write all unique matches to new csv - use this for cerating matched relations in neo4j\n",
    "import csv\n",
    "\n",
    "count=0\n",
    "dataArr=dfdb2.values\n",
    "print(len(dfdb2.values))\n",
    "for idx in range(len(dfdb2.values)):\n",
    "    print(\"ss\")\n",
    "    break\n",
    "\n",
    "with open(\"data/out/exact_outallmatches_unique_chemblid_drugnames.tsv\",'w') as outcsv: \n",
    "    writer=csv.writer(outcsv,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "    for idd in range(len(dfdb2.values)):\n",
    "        if dataArr[idd][0] in dictDBID_ChemblID.keys():\n",
    "            item=dataArr[idd]\n",
    "            cid=dictDBID_ChemblID[dataArr[idd][0]]\n",
    "            count=count+1\n",
    "            writer.writerow([cid,item[0],item[2]])       \n",
    "\n",
    "print(\"count=\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inchikey\n",
      "1601\n"
     ]
    }
   ],
   "source": [
    "#find matches based on inchikey - drugbank salts and chembl and write to csv \n",
    "import pandas as pd\n",
    "dfdbsalt =pd.read_csv('data/drugbank_salt.tsv',delimiter='\\t',encoding='utf-8')\n",
    "\n",
    "\n",
    "print(dfdbsalt.columns[3]) \n",
    "listInchiKey_salt=[]\n",
    "listInchiKeyOnly_salt=[]\n",
    "dictExactMatchInchi_saltDB={}\n",
    "listInchiKey_salt.append(dfdbsalt[dfdbsalt.columns[3]])\n",
    "count=0\n",
    "\n",
    "for item in dfdbsalt[dfdbsalt.columns[3]]:\n",
    "    count = count+1\n",
    "    item=str(item)\n",
    "    listInchiKeyOnly_salt.append(item) \n",
    "\n",
    "\n",
    "dfChemblInchi =pd.read_csv('data/chembl27inchikey_chemblids.csv',delimiter=',',encoding='utf-8') \n",
    "#add to dict chembl id as value and synonyms as key\n",
    "listChemblInchi= [str(x) for x in dfChemblInchi[dfChemblInchi.columns[0]]]\n",
    "listChemblIds=[str(x) for x in dfChemblInchi[dfChemblInchi.columns[1]]]\n",
    "\n",
    "\n",
    "dictChemblInchiIds=dict(zip(listChemblInchi,listChemblIds))\n",
    "\n",
    "for item in listInchiKeyOnly_salt: \n",
    "    if item is None or pd.isnull(item) or len(item) == 0:\n",
    "        continue\n",
    "    if item in dictChemblInchiIds:\n",
    "        dictExactMatchInchi_saltDB[item]= dictChemblInchiIds[item] \n",
    "print(len(dictExactMatchInchi_saltDB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss\n",
      "['DBSALT000105' 'Leuprolide acetate' '37JNS02E7V'\n",
      " 'YFDMUNOZURYOCP-XNHQSDQCSA-N' '74381-53-6' 1269.473 1268.666591578]\n",
      "inchi matches in salt 1601\n"
     ]
    }
   ],
   "source": [
    "#write drugbank salt inchi matches to csv\n",
    "import csv\n",
    "\n",
    "count=0\n",
    "dataArrS=dfdbsalt.values\n",
    "for idx in range(len(dfdbsalt.values)):\n",
    "    print(\"ss\")\n",
    "    print(dataArrS[idx])\n",
    "    break\n",
    "    \n",
    "#add chembl id also to csv matches file \n",
    "with open(\"data/out/outmatches_salt_inchikey_drugnames_chemblids.tsv\",'w') as outcsv2: \n",
    "    writer=csv.writer(outcsv2,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')  \n",
    "   \n",
    "    for idd in range(len(dfdbsalt.values)):\n",
    "        dbinchi=dataArrS[idd][3]\n",
    "        if dbinchi in dictExactMatchInchi_saltDB.keys():\n",
    "            count=count+1\n",
    "            item=dataArrS[idd]  \n",
    "            chemblid=dictExactMatchInchi_saltDB[dbinchi]\n",
    "            writer.writerow([chemblid,item[0],item[1]])\n",
    "print(\"inchi matches in salt\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2505\n",
      "2505\n",
      "(1961462, 2)\n",
      "1961462\n",
      "<class 'list'>\n",
      "1421\n",
      "1608\n"
     ]
    }
   ],
   "source": [
    "#find matches based on name - drugbank salts and chembl and write to csv \n",
    "import pandas as pd\n",
    "dfdbsalt =pd.read_csv('data/drugbank_salt.tsv',delimiter='\\t',encoding='utf-8')\n",
    "\n",
    "\n",
    "listSaltNames_compoundDB=[]\n",
    "listSaltExactMatchNames_compoundDB=[]\n",
    "listChemblNames=[]\n",
    "dictSaltExactMatchNames_compoundDB={}\n",
    "\n",
    "listSaltNames_compoundDB=[x.lower() for x in dfdbsalt[dfdbsalt.columns[1].lower()]]\n",
    "\n",
    "print(\"total\",len(dfdbsalt[dfdbsalt.columns[1]]))                    \n",
    "print(len(listSaltNames_compoundDB))\n",
    "\n",
    "dfChemblNames =pd.read_csv('data/chembl27_prefnames_ids.csv',delimiter='\\t',encoding='utf-8') #chembl24prefnames.csv\n",
    "print(dfChemblNames.shape)\n",
    "\n",
    "#add to list only contains names\n",
    "listChemblNames= [str(x).lower() for x in dfChemblNames[dfChemblNames.columns[0]]]\n",
    "\n",
    "print(len(listChemblNames))\n",
    "\n",
    "print(type(listChemblNames))\n",
    "\n",
    "for item in listSaltNames_compoundDB:  \n",
    "    if item is None or pd.isnull(item) or len(item) == 0:\n",
    "        continue\n",
    "    if item in listChemblNames :\n",
    "        listSaltExactMatchNames_compoundDB.append(item)\n",
    "        \n",
    "print(len(listSaltExactMatchNames_compoundDB))\n",
    "\n",
    "#add to dict chembl id as value and name as key\n",
    "listChemblNames= [str(x).lower() for x in dfChemblNames[dfChemblNames.columns[0]]]\n",
    "listChemblIds=[str(x) for x in dfChemblNames[dfChemblNames.columns[1]]]\n",
    "dictChemblNamesIds=dict(zip(listChemblNames,listChemblIds))\n",
    "\n",
    "#consider checking names in drugbank salt to synonmys in chembl\n",
    "dfChemblSynonyms =pd.read_csv('data/chembl27_synonyms_ids.csv',delimiter='\\t',encoding='utf-8')#chembl24_synonyms\n",
    "listChemblSNames= [str(x).lower() for x in dfChemblSynonyms[dfChemblSynonyms.columns[0]]]\n",
    "listChemblSIds=[str(x) for x in dfChemblSynonyms[dfChemblSynonyms.columns[1]]]\n",
    "dictChemblSIds=dict(zip(listChemblSNames,listChemblSIds))\n",
    "  \n",
    "\n",
    "        \n",
    "for item in listSaltNames_compoundDB:   \n",
    "    if item is None or pd.isnull(item) or len(item) == 0:\n",
    "        continue\n",
    "    if item in dictChemblNamesIds:\n",
    "        dictSaltExactMatchNames_compoundDB[item]= dictChemblNamesIds[item]  \n",
    "    if item in dictChemblSIds:\n",
    "        dictSaltExactMatchNames_compoundDB[item]= dictChemblSIds[item] \n",
    "      \n",
    "       \n",
    "print(len(dictSaltExactMatchNames_compoundDB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss\n",
      "['DBSALT000105' 'Leuprolide acetate' '37JNS02E7V'\n",
      " 'YFDMUNOZURYOCP-XNHQSDQCSA-N' '74381-53-6' 1269.473 1268.666591578]\n",
      "name matches in salt 1608\n"
     ]
    }
   ],
   "source": [
    "#write drugbank salt name matches to csv\n",
    "import csv\n",
    "\n",
    "count=0\n",
    "dataArrS=dfdbsalt.values\n",
    "for idx in range(len(dfdbsalt.values)):\n",
    "    print(\"ss\")\n",
    "    print(dataArrS[idx])\n",
    "    break\n",
    "    \n",
    "#add chembl id also to csv matches file \n",
    "with open(\"data/out/outmatches_salt_names_drugnames_chemblids.tsv\",'w') as outcsv2: \n",
    "    writer=csv.writer(outcsv2,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')  \n",
    "   \n",
    "    for idd in range(len(dfdbsalt.values)):\n",
    "        dbname=str(dataArrS[idd][1]).lower()\n",
    "        if dbname is None or pd.isnull(dbname) or len(dbname) == 0:\n",
    "            continue\n",
    "        if dbname in dictSaltExactMatchNames_compoundDB.keys():\n",
    "            count=count+1\n",
    "            item=dataArrS[idd]  \n",
    "            chemblid=dictSaltExactMatchNames_compoundDB[dbname]\n",
    "            writer.writerow([chemblid,item[0],item[1]])\n",
    "print(\"name matches in salt\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict total unique matches in salt 1887\n"
     ]
    }
   ],
   "source": [
    "#data fusion for drugbank salt - find unique out matches \n",
    "dictSaltDBID_ChemblID={}\n",
    "\n",
    "dfsalt_inchi =pd.read_csv('data/out/outmatches_salt_inchikey_drugnames_chemblids.tsv', header=None, delimiter=\"\\t\", encoding='utf-8')\n",
    "listSaltInchiids=dfsalt_inchi.values\n",
    "\n",
    "for item in listSaltInchiids:\n",
    "    dictSaltDBID_ChemblID[item[1]]=item[0]   \n",
    "\n",
    "    \n",
    "dfsalt_name =pd.read_csv('data/out/outmatches_salt_names_drugnames_chemblids.tsv', header=None, delimiter=\"\\t\", encoding='utf-8')\n",
    "listSaltNames=dfsalt_name.values\n",
    "for item1 in listSaltNames: \n",
    "    dbid=item1[1]\n",
    "    if dbid is None or pd.isnull(dbid) or len(dbid) == 0:\n",
    "        continue\n",
    "    if dbid not in dictSaltDBID_ChemblID.keys():\n",
    "        dictSaltDBID_ChemblID[item1[1]]=item1[0] \n",
    "        \n",
    "print(\"dict total unique matches in salt\",len(dictSaltDBID_ChemblID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2505\n",
      "ss\n",
      "count= 1887\n"
     ]
    }
   ],
   "source": [
    "#data fusion write all unique matches for salt to new csv - use this for creating matched relations in neo4j from salt_drugbank\n",
    "import csv\n",
    "\n",
    "count=0\n",
    "dataArrS=dfdbsalt.values\n",
    "print(len(dfdbsalt.values))\n",
    "for idx in range(len(dfdbsalt.values)):\n",
    "    print(\"ss\")\n",
    "    break\n",
    "\n",
    "with open(\"data/out/exact_outallmatches_unique_salt_chemblid_drugnames.tsv\",'w') as outcsv: \n",
    "    writer=csv.writer(outcsv,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "    for idd in range(len(dfdbsalt.values)):\n",
    "        if dataArrS[idd][0] is None or pd.isnull(dataArrS[idd][0]) or len(dataArrS[idd][0]) == 0:\n",
    "            continue\n",
    "        if dataArrS[idd][0] in dictSaltDBID_ChemblID.keys():\n",
    "            item=dataArrS[idd]\n",
    "            cid=dictSaltDBID_ChemblID[dataArrS[idd][0]]\n",
    "            count=count+1\n",
    "            writer.writerow([cid,item[0],item[1]])       \n",
    "\n",
    "print(\"count=\",count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------end-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvclin",
   "language": "python",
   "name": "myenvclin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
