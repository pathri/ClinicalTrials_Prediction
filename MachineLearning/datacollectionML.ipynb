{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Notebook - Data Collection for ML<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Imports<h6>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv as csv\n",
    "rom datetime import datetime \n",
    "import pytz \n",
    "  \n",
    "IST = pytz.timezone('Asia/Kolkata') \n",
    "print(\"start time\", datetime.now(IST)) \n",
    "print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Read trials_minreqfields csv. The file contains fields such as 'id', 'identifiers', 'recruitment_status', 'has_published_results', 'status', 'registration_date', 'source_id', 'study_type', 'study_phase' exported from Open Trials Postgre dump (count=358140)\n",
    "</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read trials in req fields data\n",
    "dftrials = pd.read_csv('/sas/vidhya/test/trials_minreqfields.csv',delimiter='\\t',encoding='utf-8')\n",
    "\n",
    "print(dftrials.columns) #2=name\n",
    "print(\"total columns\", len(dftrials.columns))\n",
    "print(\"total entried\", len(dftrials))\n",
    "dftrialslist=dftrials.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Read trials_interventions csv. The file contains 'trial_id' and 'intervention_id' from Open Trials data count=598880</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read trials_interv data\n",
    "dftrials_interventions= pd.read_csv('/sas/vidhya/test/trials_interventions.csv',delimiter=',',encoding='utf-8')\n",
    "\n",
    "print(dftrials_interventions.columns) #2=name\n",
    "print(\"total columns\", len(dftrials_interventions.columns))\n",
    "print(\"total entries\", len(dftrials_interventions))\n",
    "\n",
    "dftrials_interventionslist=dftrials_interventions.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Read interventions csv. This file contains fields 'id', 'name', 'type', 'created_at', 'updated_at', 'source_id', 'slug', 'description', 'icdpcs_code', 'ndc_code', 'fda_application_id. The interventions are already filtered for type=drug and drugname without these \" , /, and\"  in the content for single name drugs  (count=33616)</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read interventions data (this is already filtered for type=drug and drugname without , / and)\n",
    "dfinterventions= pd.read_csv('/sas/vidhya/test/interventions_drugs.csv',delimiter=',',encoding='utf-8')\n",
    "\n",
    "print(dfinterventions.columns) #1=name\n",
    "print(\"total columns\", len(dfinterventions.columns))\n",
    "print(\"total entries\", len(dfinterventions))\n",
    "\n",
    "dfinterventionslist=dfinterventions.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>collect all trials with status 'complete', write to file:outtrials_completed_with drugs_CT.csv (count=47501)</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/sas/vidhya/test/outtrials_completed_with drugs_CT.tsv\",'w') as outcsv2: \n",
    "    writer=csv.writer(outcsv2,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n') \n",
    "    counterFirstRow=0\n",
    "    entriesinfile_completed=0\n",
    "    for indextrials, statustrials in enumerate(dftrials[dftrials.columns[4]]):\n",
    "        \n",
    "        if statustrials != '' or statustrials != 'nan':\n",
    "            if str(statustrials).lower() == 'complete':\n",
    "                #print(\"comp\")\n",
    "                counterFirstRow= counterFirstRow+1\n",
    "                if counterFirstRow==1:\n",
    "                    writer.writerow(['id', 'identifiers', 'recruitment_status', 'has_published_results',\n",
    "       'status', 'registration_date', 'source_id', 'intervention_id','intervention_drugname', 'study_type',\n",
    "       'study_phase'])\n",
    "                    #writer.writerow(dftrialslist[indextrials])\n",
    "\n",
    "                #get intervention id based on trial id from trial_interventions\n",
    "                trialid=dftrialslist[indextrials][0]\n",
    "                #print(\"trialid\",trialid)\n",
    "                for indexinterv, trialinterv_trialid in enumerate(dftrials_interventions[dftrials_interventions.columns[0]]): \n",
    "                    if trialinterv_trialid == trialid :\n",
    "                        intervid = dftrials_interventionslist[indexinterv][1]\n",
    "                        #get drug for intervention id from interventions\n",
    "                        #print(\"intervid\",intervid)\n",
    "                        for indexint, intid in enumerate(dfinterventions[dfinterventions.columns[0]]):\n",
    "                            if intid==intervid:\n",
    "                                entriesinfile_completed=entriesinfile_completed+1\n",
    "                                print(\"write to file\",entriesinfile_completed)\n",
    "                                intervname= dfinterventionslist[indexint][1]\n",
    "                                writer.writerow([dftrialslist[indextrials][0], dftrialslist[indextrials][1],\n",
    "                                                 dftrialslist[indextrials][2],dftrialslist[indextrials][3],\n",
    "                                                 dftrialslist[indextrials][4],dftrialslist[indextrials][5],\n",
    "                                                 dftrialslist[indextrials][6],intid, intervname,\n",
    "                                                 dftrialslist[indextrials][7],dftrialslist[indextrials][8]])\n",
    "                                \n",
    "            \n",
    "                #if counterFirstRow==500:\n",
    "                    #break\n",
    "print(\"total items written to file,entriesinfile_completed=\",entriesinfile_completed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>collect all trials with status other than 'complete', balnk, 'nan', write to file:outtrials_rest_with drugs_CT.csv (count=47776)</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/sas/vidhya/test/outtrials_rest_with drugs_CT.tsv\",'w') as outcsv2: \n",
    "    writer=csv.writer(outcsv2,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n') \n",
    "    counterFirstRow=0\n",
    "    entriesinfile_rest=0\n",
    "    for indextrials, statustrials in enumerate(dftrials[dftrials.columns[4]]):\n",
    "        \n",
    "        if statustrials != '' or statustrials != 'nan':\n",
    "            if str(statustrials).lower() != 'complete':\n",
    "                #print(\"comp\")\n",
    "                counterFirstRow= counterFirstRow+1\n",
    "                if counterFirstRow==1:\n",
    "                    writer.writerow(['id', 'identifiers', 'recruitment_status', 'has_published_results',\n",
    "       'status', 'registration_date', 'source_id', 'intervention_id','intervention_drugname', 'study_type',\n",
    "       'study_phase'])\n",
    "                    #writer.writerow(dftrialslist[indextrials])\n",
    "\n",
    "                #get intervention id based on trial id from trial_interventions\n",
    "                trialid=dftrialslist[indextrials][0]\n",
    "                #print(\"trialid\",trialid)\n",
    "                for indexinterv, trialinterv_trialid in enumerate(dftrials_interventions[dftrials_interventions.columns[0]]): \n",
    "                    if trialinterv_trialid == trialid :\n",
    "                        intervid = dftrials_interventionslist[indexinterv][1]\n",
    "                        #get drug for intervention id from interventions\n",
    "                        #print(\"intervid\",intervid)\n",
    "                        for indexint, intid in enumerate(dfinterventions[dfinterventions.columns[0]]):\n",
    "                            if intid==intervid:\n",
    "                                entriesinfile_rest=entriesinfile_rest+1\n",
    "                                print(\"write to file\",entriesinfile_rest)\n",
    "                                intervname= dfinterventionslist[indexint][1]\n",
    "                                writer.writerow([dftrialslist[indextrials][0], dftrialslist[indextrials][1],\n",
    "                                                 dftrialslist[indextrials][2],dftrialslist[indextrials][3],\n",
    "                                                 dftrialslist[indextrials][4],dftrialslist[indextrials][5],\n",
    "                                                 dftrialslist[indextrials][6],intid, intervname,\n",
    "                                                 dftrialslist[indextrials][7],dftrialslist[indextrials][8]])\n",
    "                                \n",
    "            \n",
    "                #if counterFirstRow==500:\n",
    "                    #break\n",
    "print(\"total items written to file,entriesinfile_rest=\",entriesinfile_rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>\n",
    "Filtered from previous output files, outtrials_completed_with drugs_CT.tsv and outtrials_rest_with drugs_CT.tsv for labelling based on rules as below\n",
    "Pass => status = completed, phase= \"Phase 3/ Phase 4\", \"Phase 3\", \"Phase III\", \"3\", \"III\", count = 8866\n",
    "Fail => status = Suspended/Terminated/Withdrawn, phase = All except \"Not Selected\", \"N/A\", \"Not Applicable\", count= 7915\n",
    "Pass (additional phase4 only) => status = completed, phase= \"Phase 4\",\"IV\", count = 6655\n",
    "</h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Read DrugBank file and prepare Name-Id dictionary </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDB =pd.read_csv('drugbank_drug.tsv',delimiter='\\t',encoding='utf-8')\n",
    "\n",
    "print(dfDB.columns[2]) #2=name\n",
    "print(\"total columns\", len(dfDB.columns))\n",
    "\n",
    "listNames_DB=[]\n",
    "listIds_DB=[]\n",
    "listExactMatchNames_DB_T=[]\n",
    "\n",
    "\n",
    "listNames_DB=[x.lower() for x in dfDB[dfDB.columns[2].lower()]]\n",
    "listIds_DB=[x for x in dfDB[dfDB.columns[0]]]\n",
    "\n",
    "print(\"total records in column\", len(dfDB[dfDB.columns[2]]))                    \n",
    "print(len(listNames_DB))\n",
    "print(len(listIds_DB))\n",
    "print(listIds_DB[0])\n",
    "\n",
    "#add to dict drrugbank id as value and name as key\n",
    "dictDBNamesIds=dict(zip(listNames_DB,listIds_DB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Match Intervention Name - Clinical Trials and DrugBank Name for Pass</h6>\n",
    "<h6> Note: \n",
    "    outtrials_completed_withdrugs_phase3_passFinal,csv => status = Completed, phase= \"Phase 3/ Phase 4\", \"Phase 3\", \"Phase III\", \"3\", \"III\".\n",
    "    outtrials_completed_withdrugs_phase4only_pass.csv => status = Completed, phase= \"Phase 4\" </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfT =pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outtrials_completed_withdrugs_phase3_passFinal.csv',delimiter=',',encoding='utf-8')\n",
    "#rerun\n",
    "dfT =pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outtrials_completed_withdrugs_phase4only_pass.csv',delimiter=',',encoding='utf-8')\n",
    "print(dfT.columns[8]) #2=drug_ame\n",
    "print(\"total columns\", len(dfT.columns))\n",
    "print(\"columns\", dfT.columns)\n",
    "listNames_T=[]\n",
    "listNamesMatching_T=[]\n",
    "print(dfT[dfT.columns[8]][0])\n",
    "for x in dfT[dfT.columns[8]]:\n",
    "    x=str(x)\n",
    "    xnew = x.lower()\n",
    "    listNames_T.append(xnew)\n",
    "    #break\n",
    "print(\"total records in column\", len(dfT[dfT.columns[8]]))                    \n",
    "print(len(listNames_T))\n",
    "print(listNames_T[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Interim out with DrugBankID and Name for Pass </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "listExactMatchNames_DBTPass=[]\n",
    "listExactMatchNames_DBID_DBTPass=[]\n",
    "listAllMatchesPass=[]\n",
    "#write matches to csv file\n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outtrials_completed_phase4_passinterm.tsv\",'w') as outcsv2: \n",
    "    writer2=csv.writer(outcsv2,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n') \n",
    "    \n",
    "    for idx, item in enumerate(listNames_DB):        \n",
    "        if item != 'nan' :         \n",
    "            for itemCT in listNames_T:\n",
    "                if itemCT != 'nan' :\n",
    "                    if item == itemCT :            \n",
    "                        listExactMatchNames_DBTPass.append(item)\n",
    "                        DBID=listIds_DB[idx]\n",
    "                        listExactMatchNames_DBID_DBTPass.append(DBID)\n",
    "                        listAllMatchesPass.append([DBID,itemCT])\n",
    "                        writer2.writerow([DBID, item, itemCT ])\n",
    "                \n",
    "    print(\"total matched records based on names\", len(listExactMatchNames_DBTPass))\n",
    "    print(\"total matched records based on names\", len(listExactMatchNames_DBID_DBTPass))\n",
    "    print(listExactMatchNames_DBID_DBTPass[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Write all matched records and matched DrugBank Id for Pass</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "dataArrPass=dfT.values\n",
    "for x in range(len(dfT.values)):\n",
    "    print(\"ss\",x)\n",
    "    break\n",
    "\n",
    "print(\"len\", len(dfT.values))\n",
    "header=['id','identifiers','recruitment_status','has_published_results','status',\n",
    "                            'registration_date','source_id' ,'intervention_id',\n",
    "                            'intervention_drugname','study_type','study_phase','Label','drugbank id']\n",
    "\n",
    "#add drugbank id also to csv matches file \n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outtrials_completed_phase4_dbid_passFinal.tsv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for idd in range(len(dfT.values)):\n",
    "            count=count+1\n",
    "            drugnameTrials=str(dataArrPass[idd][8]).lower()\n",
    "            if drugnameTrials in dictDBNamesIds.keys():\n",
    "                for name, idval in dictDBNamesIds.items():   \n",
    "                    if drugnameTrials == name:                    \n",
    "                        item=dataArrPass[idd]  \n",
    "                        dbid=idval\n",
    "                        writer.writerow([ item[0],item[1],item[2],item[3],item[4], item[5],item[6],item[7],item[8],item[9],item[10],\n",
    "                            item[11], dbid])      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Match Intervention Name - Clinical Trials and DrugBank Name for Fail</h6>\n",
    "<h6> Note: outtrials_restsub_withdrugs_failFinal,csv => status = Suspended/Terminated/Withdrawn, phase = All except \"Not Selected\", \"N/A\", \"Not Applicable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfFT =pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outtrials_restsub_withdrugs_failFinal.csv',delimiter=',',encoding='utf-8')\n",
    "\n",
    "print(dfFT.columns[8]) #2=drug_ame\n",
    "print(\"total columns\", len(dfFT.columns))\n",
    "print(\"columns\", dfFT.columns)\n",
    "\n",
    "listNames_FT=[]\n",
    "\n",
    "listNamesMatching_FT=[]\n",
    "print(dfFT[dfFT.columns[8]][0])\n",
    "for x in dfFT[dfFT.columns[8]]:\n",
    "    x=str(x)\n",
    "    xnew = x.lower()\n",
    "    listNames_FT.append(xnew)\n",
    "    #break\n",
    "\n",
    "\n",
    "print(\"total records in column\", len(dfFT[dfFT.columns[8]]))                    \n",
    "print(len(listNames_FT))\n",
    "print(listNames_FT[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Interim out with DrugBankID and Name for Fail</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "listExactMatchNames_DBTFail=[]\n",
    "listExactMatchNames_DBID_DBTFail=[]\n",
    "listAllMatchesFail=[]\n",
    "\n",
    "#write matches to csv file\n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outtrials_rest_fail_interm.tsv\",'w') as outcsv2: \n",
    "    writer2=csv.writer(outcsv2,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')     \n",
    "    for idx, item in enumerate(listNames_DB):     \n",
    "        count=count+1        \n",
    "        if item != 'nan' :           \n",
    "            for itemCT in listNames_FT:\n",
    "                if itemCT != 'nan' : \n",
    "                    if item == itemCT :            \n",
    "                        listExactMatchNames_DBTFail.append(item)\n",
    "                        DBID=listIds_DB[idx]\n",
    "                        listExactMatchNames_DBID_DBTFail.append(DBID)\n",
    "                        listAllMatchesFail.append([DBID,itemCT])\n",
    "                        writer2.writerow([DBID, item, itemCT ])\n",
    "                \n",
    "    print(\"total matched records based on names\", len(listExactMatchNames_DBTFail))\n",
    "    print(\"total matched records based on names\", len(listExactMatchNames_DBID_DBTFail))\n",
    "    print(listExactMatchNames_FDBID_DBT[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Write all matched records amd matched DrugBank Id for Fail</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "dataArrFail=dfFT.values\n",
    "print(\"len\", len(dfFT.values))\n",
    "#add drugbank id also to csv matches file \n",
    "header=['id','identifiers','recruitment_status','has_published_results','status',\n",
    "                            'registration_date','source_id' ,'intervention_id',\n",
    "                            'intervention_drugname','study_type','study_phase','Label','drugbank id']\n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outtrials_rest_dbid_failFinal.tsv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for idd in range(len(dfFT.values)):\n",
    "            count=count+1\n",
    "            drugnameTrials=str(dataArrFail[idd][8]).lower()\n",
    "            if drugnameTrials in dictDBNamesIds.keys():\n",
    "                for name, idval in dictDBNamesIds.items():   \n",
    "                    if drugnameTrials == name:                    \n",
    "                        item=dataArrFail[idd]  \n",
    "                        dbid=idval\n",
    "                        writer.writerow([ item[0],item[1],item[2],item[3],item[4], item[5],item[6],\n",
    "                                         item[7],item[8],item[9],item[10],'Fail',dbid])          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Prepare dictionary TrialId-ConditionId from Trials_Conditions csv</h6>\n",
    "<h6>Prepare dictionary ConditionId-ConditionName from conditions_id_name csv</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get condition based on trials id and add to dict \n",
    "dfdbTC =pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/trials_conditions.csv',delimiter=',',encoding='utf-8')\n",
    "\n",
    "print(len(dfdbTC.columns))\n",
    "\n",
    "#prep dict TD,CID\n",
    "listTIds= [str(x).lower() for x in dfdbTC[dfdbTC.columns[0]]]\n",
    "listCIds=[str(x).lower() for x in dfdbTC[dfdbTC.columns[1]]]\n",
    "dictTCIds=dict(zip(listTIds,listCIds))\n",
    "for k, v in dictTCIds.items():\n",
    "    print(k,v)\n",
    "    break\n",
    "    \n",
    "#prep dict CID, CName\n",
    "dfdbC =pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/conditions_id_name.csv',delimiter=',',encoding='utf-8')\n",
    "print(dfdbC.columns)\n",
    "listCds= [str(x).lower() for x in dfdbC[dfdbC.columns[0]]]\n",
    "listCNames = [str(x).lower() for x in dfdbC[dfdbC.columns[1]]]\n",
    "dictCIdsnames =dict(zip(listCds,listCNames))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Extend data with Condition id and Condition name for Pass </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extend with condition  \n",
    "header=['id', 'identifiers', 'recruitment_status', 'has_published_results',\n",
    "       'status', 'registration_date', 'source_id', 'intervention_id',\n",
    "       'intervention_drugname', 'drugbank id',\n",
    "        'condition id', 'condition name','study_type ','study_phase', 'Label'\n",
    "       ]\n",
    "\n",
    "dataArrPass=dfT.values\n",
    "\n",
    "print(\"len\", len(dfT.values))\n",
    "print(\"columns\", len(dfT.columns))\n",
    "#add drugbank id also to csv matches file \n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outtrials_completed_phase4_dbid_condition_passFinal.tsv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for idd in range(len(dfT.values)):\n",
    "            count=count+1\n",
    "            drugnameTrials=str(dataArrPass[idd][8]).lower()\n",
    "            idTrials=str(dataArrPass[idd][0]).lower()\n",
    "            if drugnameTrials in dictDBNamesIds.keys():\n",
    "                for name, idval in dictDBNamesIds.items():   \n",
    "                    if drugnameTrials == name:                    \n",
    "                        item=dataArrPass[idd]  \n",
    "                        dbid=idval                        \n",
    "                        if idTrials in dictTCIds.keys():\n",
    "                            for tid, cid in dictTCIds.items():   \n",
    "                                if idTrials == tid:                    \n",
    "                                    item=dataArrPass[idd]  \n",
    "                                    cidval = cid\n",
    "                                    for c_id, c_name in dictCIdsnames.items():\n",
    "                                        if cidval == c_id:\n",
    "                                            cnameval = c_name                   \n",
    "                                            writer.writerow([ item[0],item[1],item[2],item[3],item[4], item[5],item[6],\n",
    "                                                     item[7], item[8],dbid,\n",
    "                                                        cidval, cnameval,\n",
    "                                                     item[9], item[10], item[11]])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Extend with data with Condition id and Condition name for Fail </h6>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "count=0\n",
    "dataArrFail=dfFT.values\n",
    "\n",
    "#add drugbank id also to csv matches file \n",
    "header=['id','identifiers','recruitment_status','has_published_results','status',\n",
    "                            'registration_date','source_id' ,'intervention_id',\n",
    "                            'intervention_drugname','drugbank id',\n",
    "                            'condition id', 'condition name',\n",
    "                            'study_type','study_phase','Label']\n",
    "\n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outtrials_rest_dbid_condition_failFinal.tsv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for idd in range(len(dfFT.values)):\n",
    "            count=count+1\n",
    "            drugnameTrials=str(dataArrFail[idd][8]).lower()\n",
    "            idTrials=str(dataArrFail[idd][0]).lower()\n",
    "\n",
    "            if drugnameTrials in dictDBNamesIds.keys():\n",
    "                for name, idval in dictDBNamesIds.items():   \n",
    "                    if drugnameTrials == name:                    \n",
    "                        item=dataArrFail[idd]  \n",
    "                        dbid=idval\n",
    "                        if idTrials in dictTCIds.keys():\n",
    "                            for tid, cid in dictTCIds.items():   \n",
    "                                if idTrials == tid:                    \n",
    "                                    item=dataArrFail[idd]  \n",
    "                                    cidval = cid\n",
    "                                    for c_id, c_name in dictCIdsnames.items():\n",
    "                                        if cidval == c_id:\n",
    "                                            cnameval = c_name                   \n",
    "                                            writer.writerow([ item[0],item[1],item[2],item[3],item[4], item[5],item[6],\n",
    "                                                     item[7], item[8],  dbid,\n",
    "                                                        cidval, cnameval,\n",
    "                                                    item[9], item[10], 'Fail'])                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Remove duplicate Trials form both Pass and Fail and consider only non blank smiles further</h6>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates pandas df \n",
    "#ref code off\n",
    "df2 =pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outtrials_completed_phase4_dbid_condition_passFinal.tsv',delimiter='\\t',encoding='utf-8')\n",
    "print(df2.columns)\n",
    "#df2new=df2.drop_duplicates(subset='id', keep=\"first\")\n",
    "df2new=df2.drop_duplicates(subset='id', keep=False)\n",
    "print(df2new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with pd.ExcelWriter('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/data_trial_drug_disease_distinct_phase4.xlsx') as writer:  \n",
    "    df2new.to_excel(writer, sheet_name='pass_phase4_wodup')    \n",
    "#df.to_csv(file_name, sep='\\t', encoding='utf-8')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Prepare dictionary Trials-Conditions to CTD-Disease dictionary_condition_to_ctd_disease</h6>\n",
    "<h6>Prepare dictionary CTD Gene to Uniport dict_gene_id_to_protein_id</h6>\n",
    "<h6>Prepare dictionary CTD Disease to CTD Gene dict_disease_to_gene</h6>\n",
    "<h6>Out csv with UniProt id(s) for Trial-Condition for Pass</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get target ids for each trials_condition\n",
    "import csv\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "print(datetime.datetime.utcnow())\n",
    "dictionary_condition_to_ctd_disease={}\n",
    "file=open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/mapping_disease.csv','r',encoding='utf-8')\n",
    "csv_reader=csv.DictReader(file, delimiter='\\t')\n",
    "for line in csv_reader:\n",
    "    disease = line['ot_disease_id']\n",
    "    if not disease in dictionary_condition_to_ctd_disease:\n",
    "        dictionary_condition_to_ctd_disease[disease]=set()\n",
    "    dictionary_condition_to_ctd_disease[disease].add(line['ctd_disease_id'])\n",
    "\n",
    "file.close()\n",
    "\n",
    "dict_gene_id_to_protein_id={}\n",
    "\n",
    "file=open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/mapping_protein_uniprot.csv','r',encoding='utf-8')\n",
    "csv_reader=csv.DictReader(file, delimiter='\\t')\n",
    "\n",
    "\n",
    "for line in csv_reader:\n",
    "    gene_id=line['ctd_gene_id']\n",
    "    if gene_id not in dict_gene_id_to_protein_id:\n",
    "        dict_gene_id_to_protein_id[gene_id]=set()\n",
    "    dict_gene_id_to_protein_id[gene_id].add(line['protein_id'])\n",
    "\n",
    "file.close()\n",
    "\n",
    "file=open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/CTD_genes_diseases.csv','r',encoding='utf-8')\n",
    "csv_reader=csv.DictReader(file, delimiter=',')\n",
    "\n",
    "print(csv_reader.fieldnames)\n",
    "dict_disease_to_gene={}\n",
    "\n",
    "for line in csv_reader:\n",
    "    direct_evidence=line['DirectEvidence']\n",
    "    if direct_evidence !='':             \n",
    "        gene_id=line['GeneID']\n",
    "        disease_id=line['DiseaseID'].replace('MESH:','')\n",
    "        if disease_id not in dict_disease_to_gene:\n",
    "            dict_disease_to_gene[disease_id]=set()\n",
    "        dict_disease_to_gene[disease_id].add(gene_id)\n",
    "\n",
    "file.close()\n",
    "#outdftrials_condn_targets_pass\n",
    "file = open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_condn_targets_pass_phase4.tsv','r',encoding='utf-8')\n",
    "csv_reader=csv.DictReader(file, delimiter='\\t')\n",
    "\n",
    "#condition_de_to_uniprot_ids_pass\n",
    "\n",
    "#file_mapped=open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/condition_to_uniprot_ids_pass.tsv','w',encoding='utf-8')\n",
    "file_mapped=open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/condition_de_to_uniprot_ids_pass_phase4.tsv','w',encoding='utf-8')\n",
    "\n",
    "csv_writer=csv.writer(file_mapped)\n",
    "csv_writer.writerow(['condition','uniprot_ids'])\n",
    "\n",
    "print(datetime.datetime.utcnow())\n",
    "print('search')\n",
    "set_of_condition_without_aa=set()\n",
    "counter_not_found=0\n",
    "counter_all=0\n",
    "counter_found=0\n",
    "counter_not_inctd=0\n",
    "for line in csv_reader:\n",
    "    counter_all+=1\n",
    "    print(\"counter_all\", counter_all)\n",
    "    found_one_mapping=False   \n",
    "    \n",
    "    disease_id= line['condition id']\n",
    "    if disease_id in dictionary_condition_to_ctd_disease:\n",
    "        ctd_diseases= dictionary_condition_to_ctd_disease[disease_id]\n",
    "        if disease_id in set_of_condition_without_aa:\n",
    "            continue\n",
    "        set_of_condition_without_aa.add(disease_id)\n",
    "\n",
    "        gene_set=set()\n",
    "        for ctd_disease_id in ctd_diseases:\n",
    "            if ctd_disease_id in dict_disease_to_gene:\n",
    "                gene_set=gene_set.union(dict_disease_to_gene[ctd_disease_id])\n",
    "\n",
    "        uniprot_ids=set()\n",
    "        for gene_id in gene_set:\n",
    "            if gene_id in dict_gene_id_to_protein_id:\n",
    "                found_one_mapping=True\n",
    "                counter_found+=1\n",
    "                uniprot_ids=uniprot_ids.union(dict_gene_id_to_protein_id[gene_id])\n",
    "        csv_writer.writerow([disease_id, \"|\".join(uniprot_ids)])\n",
    "        if not found_one_mapping:\n",
    "            counter_not_found+=1\n",
    "            print('not found')\n",
    "            print(disease_id)\n",
    "            print(gene_set)\n",
    "        if len(uniprot_ids)==1:\n",
    "            print('mapped only with on protein?')\n",
    "            print(disease_id)\n",
    "            print(gene_set)\n",
    "    #if counter_not_found==10:\n",
    "    #if counter_all == 3:\n",
    "        #print('count 10 not found')\n",
    "        #break\n",
    "\n",
    "    else:\n",
    "        counter_not_inctd+=1\n",
    "        csv_writer.writerow([disease_id, ''])\n",
    "        \n",
    "\n",
    "print(\"counter_not_inctd\", counter_not_inctd)\n",
    "print(\"counter_found\", counter_found)\n",
    "\n",
    "print(\"counter_not_found\", counter_not_found)\n",
    "print(datetime.datetime.utcnow())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Out csv with UniProt id(s) for Trial-Condition for Fail</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_condn_targets_fail.tsv','r',encoding='utf-8')\n",
    "csv_reader=csv.DictReader(file, delimiter='\\t')\n",
    "\n",
    "file_mapped=open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/condition_de_to_uniprot_ids_fail.tsv','w',encoding='utf-8')\n",
    "csv_writer=csv.writer(file_mapped)\n",
    "csv_writer.writerow(['condition','uniprot_ids'])\n",
    "\n",
    "print(datetime.datetime.utcnow())\n",
    "print('search')\n",
    "set_of_condition_without_aa=set()\n",
    "counter_not_found=0\n",
    "counter_all=0\n",
    "counter_found=0\n",
    "counter_not_inctd=0\n",
    "for line in csv_reader:\n",
    "    counter_all+=1\n",
    "    print(\"counter_all\", counter_all)\n",
    "\n",
    "    \n",
    "    #if counter_all%500==0:\n",
    "     #   print('divided by 500')\n",
    "      #  print(counter_all)\n",
    "    # if len(line['aasequence'])==0:\n",
    "    disease_id= line['condition id']\n",
    "    if disease_id in dictionary_condition_to_ctd_disease:\n",
    "        ctd_diseases= dictionary_condition_to_ctd_disease[disease_id]\n",
    "        if disease_id in set_of_condition_without_aa:\n",
    "            continue\n",
    "        set_of_condition_without_aa.add(disease_id)\n",
    "\n",
    "        gene_set=set()\n",
    "        for ctd_disease_id in ctd_diseases:\n",
    "            if ctd_disease_id in dict_disease_to_gene:\n",
    "                gene_set=gene_set.union(dict_disease_to_gene[ctd_disease_id])\n",
    "\n",
    "        uniprot_ids=set()\n",
    "        for gene_id in gene_set:\n",
    "            if gene_id in dict_gene_id_to_protein_id:\n",
    "                found_one_mapping=True\n",
    "                counter_found+=1\n",
    "                uniprot_ids=uniprot_ids.union(dict_gene_id_to_protein_id[gene_id])\n",
    "        csv_writer.writerow([disease_id, \"|\".join(uniprot_ids)])\n",
    "        if not found_one_mapping:\n",
    "            counter_not_found+=1\n",
    "            print('not found')\n",
    "            print(disease_id)\n",
    "            print(gene_set)\n",
    "        if len(uniprot_ids)==1:\n",
    "            print('mapped only with on protein?')\n",
    "            print(disease_id)\n",
    "            print(gene_set)\n",
    "    #if counter_not_found==10:\n",
    "    #if counter_all == 3:\n",
    "        #print('count 10 not found')\n",
    "        #break\n",
    "\n",
    "    else:\n",
    "        counter_not_inctd+=1\n",
    "        csv_writer.writerow([disease_id, ''])\n",
    "        \n",
    "print(\"counter_not_found\", counter_not_found)\n",
    "print(\"counter_not_inctd\", counter_not_inctd)\n",
    "print(\"counter_found\", counter_found)\n",
    "\n",
    "print(\"counter_not_found\", counter_not_found)\n",
    "print(datetime.datetime.utcnow())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Fill with blanks for the ones that are not mapped Targets not found for Trial-Condition and write to csv</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill with blanks for the ones which are not mapped (based o prev o/p)\n",
    "\n",
    "import pandas as pd\n",
    "#condition_de_to_uniprot_ids_pass\n",
    "dfctduniprot =pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/condition_de_to_uniprot_ids_pass_phase4.tsv',delimiter=',', encoding='utf-8')\n",
    "print(dfctduniprot.columns)\n",
    "\n",
    "dftrials = pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_condn_targets_pass_phase4.tsv',delimiter='\\t', encoding='utf-8')                               \n",
    "print(dftrials.columns)\n",
    "dftrialsValues=dftrials.values\n",
    "\n",
    "listcid =[str(x) for x in dfctduniprot[dfctduniprot.columns[0]]]\n",
    "listup =[str(x) for x in dfctduniprot[dfctduniprot.columns[1]]]               \n",
    "dictcid_up=dict(zip(listcid,listup))\n",
    "i=0\n",
    "\n",
    "for key, val in dictcid_up.items():\n",
    "    print(key,val)    \n",
    "    break\n",
    "header=['condition', 'Target_id']\n",
    "                            \n",
    "count=0\n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_condn_de_targets_passall_phase4.csv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter=',', lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for idd in range(len(dftrials.values)):\n",
    "            count=count+1\n",
    "            condid= dftrialsValues[idd][1]\n",
    "            \n",
    "            prots=''\n",
    "            if condid in dictcid_up.keys():\n",
    "                #print(\"inside\")\n",
    "                prots=dictcid_up[condid]\n",
    "                \n",
    "            print(\"done count=\",count )\n",
    "            \n",
    "            writer.writerow([condid,prots ])\n",
    "            #if count== 50:\n",
    "                #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Fill with blanks for the ones that are not mapped, Targets not found for Trial-Condition and write to csv</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill with blanks for the ones which are not mapped (based o prev o/p)\n",
    "\n",
    "import pandas as pd\n",
    "dfctduniprot =pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/condition_de_to_uniprot_ids_fail.tsv',delimiter=',', encoding='utf-8')\n",
    "print(dfctduniprot.columns)\n",
    "\n",
    "dftrials = pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_condn_targets_fail.tsv',delimiter='\\t', encoding='utf-8')                               \n",
    "print(dftrials.columns)\n",
    "dftrialsValues=dftrials.values\n",
    "\n",
    "listcid =[str(x) for x in dfctduniprot[dfctduniprot.columns[0]]]\n",
    "listup =[str(x) for x in dfctduniprot[dfctduniprot.columns[1]]]               \n",
    "dictcid_up=dict(zip(listcid,listup))\n",
    "\n",
    "#for key, val in dictcid_up:\n",
    "    #print(key,val)\n",
    "    #break\n",
    "header=['condition', 'Target_id']\n",
    "                            \n",
    "count=0\n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_condn_de_targets_failall.csv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter=',', lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for idd in range(len(dftrials.values)):\n",
    "            count=count+1\n",
    "            condid= dftrialsValues[idd][1]\n",
    "            \n",
    "            prots=''\n",
    "            if condid in dictcid_up.keys():\n",
    "                prots=dictcid_up[condid]\n",
    "                \n",
    "            print(\"done count=\",count )\n",
    "            \n",
    "            writer.writerow([condid,prots ])\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Get Drug Targets from CTD for Pass</h6>\n",
    "<h6>Find CTD ChemicalID mapped to DrugBankID, get CTD Geneid mapped to CTDChemical and then UniProt Id(s) mapped to CTD GeneID</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find matching ctd chemical name ad gene id\n",
    "#first get drugbank to chemical id dict\n",
    "#second get ctd chemical to ctd gene dict\n",
    "#code from CK with dict\n",
    "import csv\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "print(datetime.datetime.utcnow())\n",
    "dictionary_db_to_ctd_chemical={}\n",
    "file=open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/chemicals_drugbank.csv','r',encoding='utf-8')\n",
    "csv_reader=csv.DictReader(file, delimiter=',', quotechar=\"'\")\n",
    "for line in csv_reader:\n",
    "    dbid = line['Drugbank_id']\n",
    "    if not dbid in dictionary_db_to_ctd_chemical:\n",
    "        dictionary_db_to_ctd_chemical[dbid]=set()\n",
    "    dictionary_db_to_ctd_chemical[dbid].add(line['ChemicalID'])\n",
    "\n",
    "file.close()\n",
    "\n",
    "dictionary_ctd_chemical_to_ctd_gene={}\n",
    "\n",
    "file=open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/CTD_chem_gene_ixns.csv','r',encoding='utf-8')\n",
    "csv_reader=csv.DictReader(file, delimiter=',', quotechar=\"'\")\n",
    "for line in csv_reader:\n",
    "    chem = line['chemicalID']\n",
    "    if not chem in dictionary_ctd_chemical_to_ctd_gene:\n",
    "        dictionary_ctd_chemical_to_ctd_gene[chem]=set()\n",
    "    '''\n",
    "    'interaction_actions= line['InteractionActions'] if 'InteractionActions' in line else []\n",
    "    is_binding=False\n",
    "    interaction_actions=interaction_actions.split(\"|\")\n",
    "    for interaction_action in interaction_actions:\n",
    "        if len(interaction_actions)==1 and 'binding' in interaction_action:\n",
    "            is_binding=True\n",
    "    if is_binding:\n",
    "    '''\n",
    "    dictionary_ctd_chemical_to_ctd_gene[chem].add(line['GeneID'])\n",
    "file.close()\n",
    "\n",
    "\n",
    "dict_gene_id_to_protein_id={}\n",
    "\n",
    "file=open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/mapping_protein_uniprot.csv','r',encoding='utf-8')\n",
    "csv_reader=csv.DictReader(file, delimiter='\\t')\n",
    "\n",
    "\n",
    "for line in csv_reader:\n",
    "    gene_id=line['ctd_gene_id']\n",
    "    if gene_id not in dict_gene_id_to_protein_id:\n",
    "        dict_gene_id_to_protein_id[gene_id]=set()\n",
    "    dict_gene_id_to_protein_id[gene_id].add(line['protein_id'])\n",
    "\n",
    "file.close()\n",
    "\n",
    "#outdftrials_trials_drugbankids_pass_    outdftrials_trials_drugbankids_pass_phase4\n",
    "file = open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_trials_drugbankids_pass.tsv','r',encoding='utf-8')\n",
    "csv_reader=csv.DictReader(file, delimiter='\\t')\n",
    " \n",
    "#outdftrials_trials_drugbankids_pass drugbank_to_ctdchemical_to_bindinguniprot_ids_pass_phase4\n",
    "#file_mapped=open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/condition_to_uniprot_ids_pass.tsv','w',encoding='utf-8')\n",
    "file_mapped=open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/drugbank_to_ctdchemical_to_bindinguniprot_ids_pass.tsv','w',encoding='utf-8')\n",
    "\n",
    "csv_writer=csv.writer(file_mapped)\n",
    "csv_writer.writerow(['drugbank id','uniprot_ids'])\n",
    "\n",
    "print(datetime.datetime.utcnow())\n",
    "print('search')\n",
    "set_of_dbid=set()\n",
    "counter_not_found=0\n",
    "counter_all=0\n",
    "counter_found=0\n",
    "counter_not_inctd=0\n",
    "for line in csv_reader:\n",
    "    counter_all+=1\n",
    "    print(\"counter_all\", counter_all)\n",
    "    found_one_mapping=False\n",
    "    \n",
    " \n",
    "    dbid= line['drugbank id']\n",
    "    if dbid in dictionary_db_to_ctd_chemical:\n",
    "        ctd_chem= dictionary_db_to_ctd_chemical[dbid]\n",
    "        if dbid in set_of_dbid:\n",
    "            continue\n",
    "        set_of_dbid.add(dbid)\n",
    "\n",
    "        gene_set=set()\n",
    "        for chem in ctd_chem:\n",
    "            if chem in dictionary_ctd_chemical_to_ctd_gene:\n",
    "                gene_set=gene_set.union(dictionary_ctd_chemical_to_ctd_gene[chem])\n",
    "\n",
    "        uniprot_ids=set()\n",
    "        for gene_id in gene_set:\n",
    "            if gene_id in dict_gene_id_to_protein_id:\n",
    "                found_one_mapping=True\n",
    "                counter_found+=1\n",
    "                uniprot_ids=uniprot_ids.union(dict_gene_id_to_protein_id[gene_id])\n",
    "        csv_writer.writerow([dbid, \"|\".join(uniprot_ids)])\n",
    "        if not found_one_mapping:\n",
    "            counter_not_found+=1\n",
    "            print('not found')\n",
    "            print(dbid)\n",
    "            print(gene_set)\n",
    "        if len(uniprot_ids)==1:\n",
    "            print('mapped only with on protein?')\n",
    "            print(dbid)\n",
    "            print(gene_set)\n",
    "   \n",
    "\n",
    "    else:\n",
    "        counter_not_inctd+=1\n",
    "        csv_writer.writerow([dbid, ''])\n",
    "        \n",
    "\n",
    "print(\"counter_not_inctd\", counter_not_inctd)\n",
    "print(\"counter_found\", counter_found)\n",
    "\n",
    "print(\"counter_not_found\", counter_not_found)\n",
    "print(datetime.datetime.utcnow())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Get Drug Targets from CTD for Fail</h6>\n",
    "<h6>Find CTD ChemicalID mapped to DrugBankID, get CTD Geneid mapped to CTDChemical and then UniProt Id(s) mapped to CTD GeneID</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find matching ctd chemical name ad gene id\n",
    "#first get drugbank to chemical id dict\n",
    "#second get ctd chemical to ctd gene dict\n",
    "#code from CK with dict\n",
    "file = open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_trials_drugbankids_fail.tsv','r',encoding='utf-8')\n",
    "csv_reader=csv.DictReader(file, delimiter='\\t')\n",
    "\n",
    "#file_mapped=open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/condition_to_uniprot_ids_pass.tsv','w',encoding='utf-8')\n",
    "file_mapped=open('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/drugbank_to_ctdchemical_to_bindinguniprot_ids_fail.tsv','w',encoding='utf-8')\n",
    "\n",
    "csv_writer=csv.writer(file_mapped)\n",
    "csv_writer.writerow(['drugbank id','uniprot_ids'])\n",
    "\n",
    "print(datetime.datetime.utcnow())\n",
    "print('search')\n",
    "set_of_dbid=set()\n",
    "counter_not_found=0\n",
    "counter_all=0\n",
    "counter_found=0\n",
    "counter_not_inctd=0\n",
    "for line in csv_reader:\n",
    "    counter_all+=1\n",
    "    print(\"counter_all\", counter_all)    \n",
    "   \n",
    "    dbid= line['drugbank id']\n",
    "    if dbid in dictionary_db_to_ctd_chemical.keys():\n",
    "        ctd_chem= dictionary_db_to_ctd_chemical[dbid]\n",
    "        if dbid in set_of_dbid:\n",
    "            continue\n",
    "        set_of_dbid.add(dbid)\n",
    "    \n",
    "        gene_set=set()\n",
    "        for chem in ctd_chem:\n",
    "            if chem in dictionary_ctd_chemical_to_ctd_gene.keys():\n",
    "                gene_set=gene_set.union(dictionary_ctd_chemical_to_ctd_gene[chem])\n",
    "    \n",
    "        uniprot_ids=set()\n",
    "        for gene_id in gene_set:\n",
    "            if gene_id in dict_gene_id_to_protein_id:\n",
    "                found_one_mapping=True\n",
    "                counter_found+=1\n",
    "                uniprot_ids=uniprot_ids.union(dict_gene_id_to_protein_id[gene_id])\n",
    "        csv_writer.writerow([dbid, \"|\".join(uniprot_ids)])\n",
    "        if not found_one_mapping:\n",
    "            counter_not_found+=1\n",
    "            print('not found')\n",
    "            print(dbid)\n",
    "            print(gene_set)\n",
    "        if len(uniprot_ids)==1:\n",
    "            print('mapped only with on protein?')\n",
    "            print(dbid)\n",
    "            print(gene_set)\n",
    "  \n",
    "\n",
    "    else:\n",
    "        counter_not_inctd+=1\n",
    "        csv_writer.writerow([dbid, ''])\n",
    "       \n",
    "    #if counter_all == 2:\n",
    "        #break\n",
    "\n",
    "print(\"counter_not_inctd\", counter_not_inctd)\n",
    "print(\"counter_found\", counter_found)\n",
    "\n",
    "print(\"counter_not_found\", counter_not_found)\n",
    "print(datetime.datetime.utcnow())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Fill with blanks for the ones that are not mapped, targets not found for CTD Chemical and write to csv</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill with blanks for the ones which are not mapped (based o prev o/p)\n",
    "\n",
    "import pandas as pd\n",
    "#drugbank_to_ctdchemical_to_uniprot_ids_pass drugbank_to_ctdchemical_to_bindinguniprot_ids_pass drugbank_to_ctdchemical_to_bindinguniprot_ids_pass_phase4\n",
    "dfctduniprot =pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/drugbank_to_ctdchemical_to_bindinguniprot_ids_pass.tsv',delimiter=',', encoding='utf-8')\n",
    "print(dfctduniprot.columns)\n",
    "\n",
    "#outdftrials_trials_drugbankids_pass\n",
    "\n",
    "dftrials = pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_trials_drugbankids_pass.tsv',delimiter='\\t', encoding='utf-8')                               \n",
    "print(dftrials.columns)\n",
    "dftrialsValues=dftrials.values\n",
    "\n",
    "listcid =[str(x) for x in dfctduniprot[dfctduniprot.columns[0]]]\n",
    "listup =[str(x) for x in dfctduniprot[dfctduniprot.columns[1]]]               \n",
    "dictcid_up=dict(zip(listcid,listup))\n",
    "\n",
    "#for key, val in dictcid_up:\n",
    "    #print(key,val)\n",
    "    #break\n",
    "header=['Drugbank id', 'CTD_UniprotTarget_id']\n",
    "                            \n",
    "count=0\n",
    "#outdftrials_trials_drugbankids_passall\n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_trials_drugbankids_passall_.csv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter=',', lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for idd in range(len(dftrials.values)):\n",
    "            count=count+1\n",
    "            dbid= dftrialsValues[idd][1]\n",
    "            \n",
    "            prots=''\n",
    "            if dbid in dictcid_up.keys():\n",
    "                prots=dictcid_up[dbid]\n",
    "                \n",
    "            print(\"done count=\",count )\n",
    "            \n",
    "            writer.writerow([dbid,prots ])\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Fill with blanks for the ones that are not mapped, Targets not found for CTD Chemical and write to csv</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill with blanks for the ones which are not mapped (based o prev o/p)\n",
    "import pandas as pd\n",
    "dfctduniprot =pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/drugbank_to_ctdchemical_to_bindinguniprot_ids_fail.tsv',delimiter=',', encoding='utf-8')\n",
    "print(dfctduniprot.columns)\n",
    "\n",
    "dftrials = pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_trials_drugbankids_fail.tsv',delimiter='\\t', encoding='utf-8')                               \n",
    "print(dftrials.columns)\n",
    "dftrialsValues=dftrials.values\n",
    "\n",
    "listcid =[str(x) for x in dfctduniprot[dfctduniprot.columns[0]]]\n",
    "listup =[str(x) for x in dfctduniprot[dfctduniprot.columns[1]]]               \n",
    "dictcid_up=dict(zip(listcid,listup))\n",
    "\n",
    "#for key, val in dictcid_up:\n",
    "    #print(key,val)\n",
    "    #break\n",
    "header=['Drugbank id', 'CTD_UniprotTarget_id']\n",
    "                            \n",
    "count=0\n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_trials_drugbankids_failall_.csv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter=',', lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for idd in range(len(dftrials.values)):\n",
    "            count=count+1\n",
    "            dbid= dftrialsValues[idd][1]\n",
    "            \n",
    "            prots=''\n",
    "            if dbid in dictcid_up.keys():\n",
    "                prots=dictcid_up[dbid]\n",
    "                \n",
    "            print(\"done count=\",count )\n",
    "            \n",
    "            writer.writerow([dbid,prots ])\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Find common targets between Disease Targets (CTD) and Drug Targets (DrugBank,CTD) for Pass</h6>\n",
    "<h6>Write output to csv files, matched in drugbank, matched in csv, all matched and non matched for Pass</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find intersections ctd disease targets and drugbank,ctd targets \n",
    "import numpy as np\n",
    "dfMatchedTargets_pass= pd.read_excel('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/ML_data_trial_drug_disease_prot.xlsx',\n",
    "                                  sheet_name='phase4_dbctdtargets_distargets') #pass_dbctdtargets_distargets\n",
    "\n",
    "print(dfMatchedTargets_pass.columns)\n",
    "dfMatchedTargets_passValues=dfMatchedTargets_pass.values\n",
    "header=['index', 'trial_id', 'intervention_id', 'intervention_name', 'drugbank', 'SMILES', 'drugbank_targets',\n",
    "        'ctd_targets', 'ctd_alltargets', 'condition id', 'condition name', 'disease_targets',  'Label','common_targets']\n",
    "                            \n",
    "                           \n",
    "count=0\n",
    "matchedindbcount=0\n",
    "matchedinctdcount=0\n",
    "nonmatchedcount=0\n",
    "countctdnotnull=0\n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/data_allcommon_targets_distargets_pass_phase4.csv\",'w') as outcsv0:\n",
    "   \n",
    "    with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/common_dbtargets_distargets_pass_phase4.csv\",'w') as outcsv:\n",
    "        with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/common_ctdtargets_distargets_pass_phase4.csv\",'w') as outcsv2: \n",
    "        \n",
    "            with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/nonmatched_dbctdtargets_distargets_pass_phase4.csv\",'w') as outcsv3: \n",
    "                writer=csv.writer(outcsv,delimiter=',', lineterminator='\\n')\n",
    "                writer.writerow(header)\n",
    "                writer2=csv.writer(outcsv2,delimiter=',', lineterminator='\\n')\n",
    "                writer2.writerow(header)\n",
    "                writer3=csv.writer(outcsv3,delimiter=',', lineterminator='\\n')\n",
    "                writer3.writerow(header)\n",
    "                writer0=csv.writer(outcsv0,delimiter=',', lineterminator='\\n')\n",
    "                writer0.writerow(header)\n",
    "                for idd in range(len(dfMatchedTargets_pass.values)):\n",
    "                    count=count+1\n",
    "                    matcheddb=False\n",
    "                    matchedctd=False\n",
    "                \n",
    "                    item=dfMatchedTargets_passValues[idd] \n",
    "                    dbtargets=dfMatchedTargets_passValues[idd][6]\n",
    "                    ctddrugtargets=dfMatchedTargets_passValues[idd][7]\n",
    "                    distargets=str(dfMatchedTargets_passValues[idd][11])\n",
    "                    if distargets != 'nan' and distargets != '':\n",
    "                        countctdnotnull+=1\n",
    "                        distargetlist= str(distargets).split('|')\n",
    "                        #print(\"distargetlist\",distargetlist)\n",
    "                        dbtlist=str(dbtargets).split(',')\n",
    "                        #print(\"dbtlist\",dbtlist)\n",
    "                        for target in dbtlist:\n",
    "                            if distargetlist.count(target) > 0 :\n",
    "                                #print(\"inside db\")\n",
    "                                matchedindbcount=matchedindbcount+1  \n",
    "                                matcheddb=True                               \n",
    "                                break\n",
    "                        if matcheddb :\n",
    "                            commonitemsdb_dis = [x for x in dbtlist if x in distargetlist]\n",
    "                            strcommonitemsdb_dis= '|'.join([str(elem) for elem in commonitemsdb_dis]) \n",
    "                            itemnew = np.append(item, strcommonitemsdb_dis)                            \n",
    "                            writer.writerow(itemnew)\n",
    "                            writer0.writerow(itemnew)\n",
    "                    \n",
    "                        else:\n",
    "                            #find ctd drugtarget matches\n",
    "                            ctddrugtargets=str(ctddrugtargets).split('|')\n",
    "                            #print(\"ctddrugtargets\",ctddrugtargets)\n",
    "                            for ctdtarget in ctddrugtargets:\n",
    "                                if distargetlist.count(ctdtarget) > 0 :\n",
    "                                    #print(\"inside ctd\")\n",
    "                                    matchedinctdcount=matchedinctdcount+1                                \n",
    "                                    matchedctd=True                        \n",
    "                                    break\n",
    "                            if matchedctd :\n",
    "                                commonitemsctd_dis = [x for x in ctddrugtargets if x in distargetlist]\n",
    "                                strcommonitemsctd_dis= '|'.join([str(elem) for elem in commonitemsctd_dis]) \n",
    "                                itemnew = np.append(item, strcommonitemsctd_dis)                            \n",
    "\n",
    "                                writer2.writerow(itemnew) \n",
    "                                writer0.writerow(itemnew)\n",
    "                        \n",
    "                            else:\n",
    "                                #print(\"non match\")\n",
    "                                nonmatchedcount=nonmatchedcount+1\n",
    "                                itemnew = np.append(item, '')  \n",
    "                                writer3.writerow(itemnew)\n",
    "        \n",
    "                    \n",
    "          \n",
    "                #print(\"done count=\",count )\n",
    "            \n",
    "                    #if count== 10:\n",
    "                        #break\n",
    "print(\"countctdnotnull\", countctdnotnull)\n",
    "print(\"matcheddb =\",matchedindbcount )\n",
    "print(\"matchedinctdcount =\",matchedinctdcount )\n",
    "print(\"nonmatchedcount=\",nonmatchedcount )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Find common targets between Disease Targets (CTD) and Drug Targets (DrugBank,CTD) for Fail</h6>\n",
    "<h6>Write output to csv files, matched in drugbank, matched in csv, all matched and non matched for Fail</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find intersections ctd disease targets and drugbank targets \n",
    "dfMatchedTargets_pass= pd.read_excel('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/ML_data_trial_drug_disease_prot.xlsx',\n",
    "                                  sheet_name='fail_dbctdtargets_distargets')\n",
    "\n",
    "print(dfMatchedTargets_pass.columns)\n",
    "dfMatchedTargets_passValues=dfMatchedTargets_pass.values\n",
    "header=['index', 'trial_id', 'intervention_id', 'intervention_name', 'drugbank', 'SMILES', 'drugbank_targets',\n",
    "        'ctd_targets','ctd_targets', 'condition id', 'condition name', 'disease_targets',  'Label','common_targets']\n",
    "                            \n",
    "\n",
    "                           \n",
    "count=0\n",
    "matchedindbcount=0\n",
    "matchedinctdcount=0\n",
    "nonmatchedcount=0\n",
    "countctdnotnull=0\n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/data_allcommon_targets_distargets_fail.csv\",'w') as outcsv0:\n",
    "   \n",
    "    with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/common_dbtargets_distargets_fail.csv\",'w') as outcsv:\n",
    "        with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/common_ctdtargets_distargets_fail.csv\",'w') as outcsv2: \n",
    "        \n",
    "            with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/nonmatched_dbctdtargets_distargets_fail.csv\",'w') as outcsv3: \n",
    "                writer=csv.writer(outcsv,delimiter=',', lineterminator='\\n')\n",
    "                writer.writerow(header)\n",
    "                writer2=csv.writer(outcsv2,delimiter=',', lineterminator='\\n')\n",
    "                writer2.writerow(header)\n",
    "                writer3=csv.writer(outcsv3,delimiter=',', lineterminator='\\n')\n",
    "                writer3.writerow(header)\n",
    "                writer0=csv.writer(outcsv0,delimiter=',', lineterminator='\\n')\n",
    "                writer0.writerow(header)\n",
    "                for idd in range(len(dfMatchedTargets_pass.values)):\n",
    "                    count=count+1\n",
    "                    matcheddb=False\n",
    "                    matchedctd=False\n",
    "                \n",
    "                    item=dfMatchedTargets_passValues[idd] \n",
    "                    dbtargets=dfMatchedTargets_passValues[idd][6]\n",
    "                    ctddrugtargets=dfMatchedTargets_passValues[idd][7]\n",
    "                    distargets=str(dfMatchedTargets_passValues[idd][10])\n",
    "                    if distargets != 'nan' and distargets != '':\n",
    "                        countctdnotnull+=1\n",
    "                        distargetlist= str(distargets).split('|')\n",
    "                        #print(\"distargetlist\",distargetlist)\n",
    "                        dbtlist=str(dbtargets).split(',')\n",
    "                        #print(\"dbtlist\",dbtlist)\n",
    "                        for target in dbtlist:\n",
    "                            if distargetlist.count(target) > 0 :\n",
    "                                #print(\"inside db\")\n",
    "                                matchedindbcount=matchedindbcount+1  \n",
    "                                matcheddb=True                               \n",
    "                                break\n",
    "                        if matcheddb :\n",
    "                            commonitemsdb_dis = [x for x in dbtlist if x in distargetlist]\n",
    "                            strcommonitemsdb_dis= '|'.join([str(elem) for elem in commonitemsdb_dis]) \n",
    "                            itemnew = np.append(item, strcommonitemsdb_dis)                            \n",
    "                            writer.writerow(itemnew)\n",
    "                            writer0.writerow(itemnew)\n",
    "                    \n",
    "                        else:\n",
    "                            #find ctd drugtarget matches\n",
    "                            ctddrugtargets=str(ctddrugtargets).split('|')\n",
    "                            #print(\"ctddrugtargets\",ctddrugtargets)\n",
    "                            for ctdtarget in ctddrugtargets:\n",
    "                                if distargetlist.count(ctdtarget) > 0 :\n",
    "                                    #print(\"inside ctd\")\n",
    "                                    matchedinctdcount=matchedinctdcount+1                                \n",
    "                                    matchedctd=True                        \n",
    "                                    break\n",
    "                            if matchedctd :\n",
    "                                commonitemsctd_dis = [x for x in ctddrugtargets if x in distargetlist]\n",
    "                                strcommonitemsctd_dis= '|'.join([str(elem) for elem in commonitemsctd_dis]) \n",
    "                                itemnew = np.append(item, strcommonitemsctd_dis)                            \n",
    "\n",
    "                                writer2.writerow(itemnew) \n",
    "                                writer0.writerow(itemnew)\n",
    "                        \n",
    "                            else:\n",
    "                                #print(\"non match\")\n",
    "                                nonmatchedcount=nonmatchedcount+1\n",
    "                                itemnew = np.append(item, '')  \n",
    "                                writer3.writerow(itemnew)\n",
    "                 \n",
    "          \n",
    "               \n",
    "print(\"countctdnotnull\", countctdnotnull)\n",
    "print(\"matcheddb =\",matchedindbcount )\n",
    "print(\"matchedinctdcount =\",matchedinctdcount )\n",
    "print(\"nonmatchedcount=\",nonmatchedcount )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Get all calculated properties from DrugBank and store in dicts</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drugbank calc prop\n",
    "import pandas as pd\n",
    "dfDB =pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/drugbank_drug.tsv',delimiter='\\t',encoding='utf-8')\n",
    "print(dfDB.columns)\n",
    "print(dfDB.columns[45]) #calculated_properties_kind_value_source\n",
    "#Molecular Weight\n",
    "listcalcpropDB=[]\n",
    "dictdbid_mw={}\n",
    "dictdbid_psa={}\n",
    "dictdbid_hba={}\n",
    "dictdbid_hbd={}\n",
    "dictdbid_rbc={}\n",
    "dictdbid_pc={}\n",
    "dictdbid_r={}\n",
    "\n",
    "listcalcpropDB.append(dfDB[dfDB.columns[45]])\n",
    "listdbids=[str(x) for x in dfDB[dfDB.columns[0]]]\n",
    "\n",
    "for idx, item in enumerate(listcalcpropDB[0]):\n",
    "    item=str(item)\n",
    "    if item != 'nan':\n",
    "        arr = item.split('||')\n",
    "        arr2=[]\n",
    "        for item in arr:\n",
    "            if 'Molecular Weight' in item:\n",
    "                arr2.append(item)\n",
    "                for item in arr2:\n",
    "                    val = item.split('::')\n",
    "                    keydbid=listdbids[idx]\n",
    "                    valmw=val[1]\n",
    "                    dictdbid_mw[keydbid]=valmw\n",
    "           \n",
    "            if 'Polar Surface Area' in item: \n",
    "                arr2.append(item)\n",
    "                for item in arr2:\n",
    "                    val = item.split('::')\n",
    "                    keydbid=listdbids[idx]\n",
    "                    valmw=val[1]\n",
    "                    dictdbid_psa[keydbid]=valmw\n",
    "           \n",
    "                \n",
    "            if 'Rotatable Bond Count' in item: \n",
    "                arr2.append(item)\n",
    "                for item in arr2:\n",
    "                    val = item.split('::')\n",
    "                    keydbid=listdbids[idx]\n",
    "                    valmw=val[1]\n",
    "                    dictdbid_rbc[keydbid]=valmw\n",
    "           \n",
    "                \n",
    "            if 'H Bond Acceptor Count' in item: \n",
    "                arr2.append(item)\n",
    "                for item in arr2:\n",
    "                    val = item.split('::')\n",
    "                    keydbid=listdbids[idx]\n",
    "                    valmw=val[1]\n",
    "                    dictdbid_hba[keydbid]=valmw\n",
    "           \n",
    "                \n",
    "            if 'H Bond Donor Count' in item: \n",
    "                arr2.append(item)\n",
    "                for item in arr2:\n",
    "                    val = item.split('::')\n",
    "                    keydbid=listdbids[idx]\n",
    "                    valmw=val[1]\n",
    "                    dictdbid_hbd[keydbid]=valmw\n",
    "           \n",
    "            \n",
    "            #Physiological Charge\n",
    "            if 'Physiological Charge' in item: \n",
    "                arr2.append(item)\n",
    "                for item in arr2:\n",
    "                    val = item.split('::')\n",
    "                    keydbid=listdbids[idx]\n",
    "                    valmw=val[1]\n",
    "                    dictdbid_pc[keydbid]=valmw\n",
    "           \n",
    "                \n",
    "            if 'Number of Rings' in item: \n",
    "                arr2.append(item)\n",
    "                for item in arr2:\n",
    "                    val = item.split('::')\n",
    "                    keydbid=listdbids[idx]\n",
    "                    valmw=val[1]\n",
    "                    dictdbid_r[keydbid]=valmw\n",
    "           \n",
    "\n",
    "print(\"total mw in db\", len(dictdbid_mw)) \n",
    "print(\"total dictdbid_psa in db\", len(dictdbid_psa))\n",
    "print(\"total dictdbid_rbc in db\", len(dictdbid_rbc))\n",
    "print(\"total dictdbid_hba in db\", len(dictdbid_hba))\n",
    "print(\"total dictdbid_hbd in db\", len(dictdbid_hbd))\n",
    "print(\"total dictdbid_pc in db\", len(dictdbid_pc))\n",
    "print(\"total dictdbid_r in db\", len(dictdbid_r))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Add data for all calculated properties from DrugBank based on DrugBank ID for Pass</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add drug properties from drugbank  for pass\n",
    "#populate other details based on drugbankid\n",
    "#extend output sheet with protein id and protein sequences\n",
    "dftrials_pass = pd.read_excel('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/ML_data_trial_drug_disease_prot.xlsx',\n",
    "                                  sheet_name='phase4_common_drugtargets_distargets')\n",
    "print(dftrials_pass.columns)\n",
    "dftrials_passValues=dftrials_pass.values\n",
    "#add drugbank id also to csv matches file \n",
    "header=['DrugBank ID', 'Molecular Weight', 'Polar Surface Area', 'H Bond Acceptor Count',\n",
    "        'H Bond Donor Count','Rotatable Bond Count','Number of Rings',\n",
    "                            'Physiological Charge']\n",
    "count=0\n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_drugbank_calcprop_pass_phase4.tsv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for idd in range(len(dftrials_pass.values)):\n",
    "            count=count+1\n",
    "            dbid= dftrials_passValues[idd][4]\n",
    "            mw=''\n",
    "            psa=''\n",
    "            hba=''\n",
    "            hbd=''\n",
    "            rbc=''\n",
    "            nr=''\n",
    "            pc=''\n",
    "            \n",
    "            if dbid in dictdbid_mw.keys():\n",
    "                mw=dictdbid_mw[dbid]   \n",
    "            if dbid in dictdbid_psa .keys():\n",
    "                psa=dictdbid_psa[dbid]   \n",
    "            if dbid in dictdbid_rbc .keys():\n",
    "                rbc=dictdbid_rbc[dbid]   \n",
    "            if dbid in dictdbid_hba.keys():\n",
    "                hba=dictdbid_hba[dbid]   \n",
    "            if dbid in dictdbid_hbd.keys():\n",
    "                hbd=dictdbid_hbd[dbid]   \n",
    "            if dbid in dictdbid_pc.keys():\n",
    "                pc=dictdbid_pc[dbid]  \n",
    "            if dbid in dictdbid_r.keys():\n",
    "                nr=dictdbid_r[dbid]  \n",
    "            \n",
    "            print(count)\n",
    "            writer.writerow([ dbid,mw,psa,hba,hbd, rbc, nr, pc ])\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Add data for all calculated properties from DrugBank based on DrugBank ID for Fail</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add drug properties from drugbank  for pass\n",
    "#populate other details based on drugbankid\n",
    "#extend output sheet with protein id and protein sequences\n",
    "dftrials_pass = pd.read_excel('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/ML_data_trial_drug_disease_prot.xlsx',\n",
    "                                  sheet_name='fail_common_drugtargets_distargets')\n",
    "print(dftrials_pass.columns)\n",
    "dftrials_passValues=dftrials_pass.values\n",
    "#add drugbank id also to csv matches file \n",
    "header=['DrugBank ID', 'Molecular Weight', 'Polar Surface Area', 'H Bond Acceptor Count',\n",
    "        'H Bond Donor Count','Rotatable Bond Count','Number of Rings',\n",
    "                            'Physiological Charge']\n",
    "count=0\n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_drugbank_calcprop_fail.tsv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter='\\t',quotechar='|',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for idd in range(len(dftrials_pass.values)):\n",
    "            count=count+1\n",
    "            dbid= dftrials_passValues[idd][4]\n",
    "            mw=''\n",
    "            psa=''\n",
    "            hba=''\n",
    "            hbd=''\n",
    "            rbc=''\n",
    "            nr=''\n",
    "            pc=''\n",
    "            \n",
    "            if dbid in dictdbid_mw.keys():\n",
    "                mw=dictdbid_mw[dbid]   \n",
    "            if dbid in dictdbid_psa .keys():\n",
    "                psa=dictdbid_psa[dbid]   \n",
    "            if dbid in dictdbid_rbc .keys():\n",
    "                rbc=dictdbid_rbc[dbid]   \n",
    "            if dbid in dictdbid_hba.keys():\n",
    "                hba=dictdbid_hba[dbid]   \n",
    "            if dbid in dictdbid_hbd.keys():\n",
    "                hbd=dictdbid_hbd[dbid]   \n",
    "            if dbid in dictdbid_pc.keys():\n",
    "                pc=dictdbid_pc[dbid]  \n",
    "            if dbid in dictdbid_r.keys():\n",
    "                nr=dictdbid_r[dbid]  \n",
    "            \n",
    "            print(count)\n",
    "            writer.writerow([ dbid,mw,psa,hba,hbd, rbc, nr, pc ])\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Get properties from UniProt and store in dicts</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare uniport dict\n",
    "import pandas as pd\n",
    "dfuniprot =pd.read_csv('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/uniprot.tsv',delimiter='\\t',encoding='utf-8')\n",
    "print(dfuniprot.columns)\n",
    "dfuniprotValues=dfuniprot.values\n",
    "dictpid_sequenceLength={}\n",
    "dictpid_pfam={}\n",
    "dictpid_goclassifiers={}\n",
    "dictpid_subcellularlocation={}\n",
    "dictpid_pathway={}\n",
    "dictpid_as={}\n",
    "\n",
    "listupids=[str(x) for x in dfuniprot[dfuniprot.columns[3]]]\n",
    "listupsequenceLength=[str(x) for x in dfuniprot[dfuniprot.columns[2]]]\n",
    "listupas=[str(x) for x in dfuniprot[dfuniprot.columns[8]]]\n",
    "listuppfam=[str(x) for x in dfuniprot[dfuniprot.columns[12]]]\n",
    "listupgo=[str(x) for x in dfuniprot[dfuniprot.columns[14]]]\n",
    "listupsubcellloc=[str(x) for x in dfuniprot[dfuniprot.columns[16]]]\n",
    "listuppathway =[str(x) for x in dfuniprot[dfuniprot.columns[19]]]\n",
    "                  \n",
    "dictpid_sequenceLength=dict(zip(listupids,listupsequenceLength))\n",
    "dictpid_as=dict(zip(listupids,listupas))\n",
    "                  \n",
    "dictpid_pfam=dict(zip(listupids,listuppfam))\n",
    "dictpid_goclassifiers=dict(zip(listupids,listupgo))\n",
    "\n",
    "dictpid_subcellularlocation=dict(zip(listupids,listupsubcellloc))\n",
    "dictpid_pathway=dict(zip(listupids,listuppathway))\n",
    "\n",
    "\n",
    "for key, value in dictpid_sequenceLength.items() :\n",
    "    print(key, value)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Add data for Target properties from UniProt based on UniProt ID for Pass</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate other details based on uniprotid\n",
    "dftrials_pass = pd.read_excel('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/ML_data_trial_drug_disease_prot.xlsx',\n",
    "                                  sheet_name='phase4_common_drugtargets_distargets')#pass_common_drugtargets_distargets\n",
    "print(dftrials_pass.columns)\n",
    "dftrials_passValues=dftrials_pass.values\n",
    "header=['Trial_id', 'Target_id', 'count_commontargets', 'sequenceLength', 'as_sequence', 'pfam',\n",
    "        'go_classifiers','subcellular_location','pathway']\n",
    "                            \n",
    "count=0\n",
    "singletarget=0\n",
    "multitarget=0\n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_drugdistarget_prop_pass_phase4.tsv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter='\\t',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for idd in range(len(dftrials_pass.values)):\n",
    "            count=count+1\n",
    "            trialid= dftrials_passValues[idd][1]\n",
    "            protid= dftrials_passValues[idd][12]\n",
    "            seqlength=''\n",
    "            seq=''\n",
    "            pfam=''\n",
    "            goc=''\n",
    "            subcel=''\n",
    "            pathway=''\n",
    "            totalcommontargets=0\n",
    "            \n",
    "            if '|' in protid:\n",
    "                #print(\"multiple targets\")\n",
    "                multitarget+=1\n",
    "                prots=protid.split(\"|\")\n",
    "                totalcommontargets=len(prots)\n",
    "                #print(\"totalcommontargets\",totalcommontargets)\n",
    "                for pid in prots:\n",
    "                    if pid in dictpid_as.keys():\n",
    "                        #print(\"in---\", pid)\n",
    "                        if seqlength == '':                            \n",
    "                            seqlength=dictpid_sequenceLength[pid]\n",
    "                            seqlengthonly=seqlength.replace('AA','')\n",
    "                            seq=dictpid_as[pid]  \n",
    "                            seqonly=seq.split(':')[1]\n",
    "                            pfam=dictpid_pfam[pid]\n",
    "                            #print(\"in if\", pfam)\n",
    "                            goc=dictpid_goclassifiers[pid] \n",
    "                            subcel=dictpid_subcellularlocation[pid]\n",
    "                            pathway=dictpid_pathway[pid]\n",
    "                        else:\n",
    "                            \n",
    "                            existingseqlength= int(seqlengthonly)\n",
    "                            newseqlength = dictpid_sequenceLength[pid]\n",
    "                            newseqlength=newseqlength.replace('AA','')\n",
    "                            seqlengthonly= existingseqlength + int(newseqlength)\n",
    "                            seq=dictpid_as[pid]  \n",
    "                            newseqonly=seq.split(':')[1]\n",
    "                            seqonly = seqonly + '::'+newseqonly\n",
    "                            newpfam=dictpid_pfam[pid]\n",
    "                            pfam = pfam + '::' +newpfam\n",
    "                            #print(\"in else newpfam\", newpfam)\n",
    "                            #print(\"in else pfam\", pfam)\n",
    "                            newgoc=dictpid_goclassifiers[pid] \n",
    "                            goc= goc +'::'+ newgoc\n",
    "                            newsubcel=dictpid_subcellularlocation[pid]\n",
    "                            subcel= subcel + '::'+  newsubcel\n",
    "                            \n",
    "                            newpathway=dictpid_pathway[pid]\n",
    "                            pathway = pathway +  '::'+newpathway                           \n",
    "                \n",
    "                    \n",
    "            else:\n",
    "                totalcommontargets=1\n",
    "                #print(\"single targets\")\n",
    "                singletarget+=1\n",
    "                if protid in dictpid_as.keys():\n",
    "                    ctargetcount=1\n",
    "                    seqlength=dictpid_sequenceLength[protid]\n",
    "                    seqlengthonly=seqlength.replace('AA','')\n",
    "                    seq=dictpid_as[protid]  \n",
    "                    seqonly=seq.split(':')[1]\n",
    "                    pfam=dictpid_pfam[protid]\n",
    "                    #print(\"only one target\", pfam)\n",
    "                    goc=dictpid_goclassifiers[protid] \n",
    "                    subcel=dictpid_subcellularlocation[protid]\n",
    "                    pathway=dictpid_pathway[protid] \n",
    "            \n",
    "            print(\"done count=\",count )\n",
    "        \n",
    "            writer.writerow([trialid, protid, totalcommontargets, seqlengthonly, seqonly, pfam, goc, subcel, pathway ])\n",
    "            #if count == 3:\n",
    "                #break\n",
    "print(\"singletarget=\",singletarget)\n",
    "print(\"multitarget\",multitarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Add data for Target properties from UniProt based on UniProt ID for Fail</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate other details based on uniprotid\n",
    "dftrials_pass = pd.read_excel('/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/ML_data_trial_drug_disease_prot.xlsx',\n",
    "                                  sheet_name='fail_common_drugtargets_distargets')\n",
    "print(dftrials_pass.columns)\n",
    "dftrials_passValues=dftrials_pass.values\n",
    "header=['Trial_id', 'Target_id', 'count_commontargets', 'sequenceLength', 'as_sequence', 'pfam',\n",
    "        'go_classifiers','subcellular_location','pathway']\n",
    "                            \n",
    "count=0\n",
    "singletarget=0\n",
    "multitarget=0\n",
    "with open(\"/sas/vidhya/CompoundDb4jV2/ClinicalTrials/MLData/outdftrials_drugdistarget_prop_fail.tsv\",'w') as outcsv: \n",
    "        writer=csv.writer(outcsv,delimiter='\\t',quoting=csv.QUOTE_MINIMAL,lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for idd in range(len(dftrials_pass.values)):\n",
    "            count=count+1\n",
    "            trialid= dftrials_passValues[idd][1]\n",
    "            protid= dftrials_passValues[idd][12]\n",
    "            seqlength=''\n",
    "            seq=''\n",
    "            pfam=''\n",
    "            goc=''\n",
    "            subcel=''\n",
    "            pathway=''\n",
    "            totalcommontargets=0\n",
    "            \n",
    "            if '|' in protid:\n",
    "                #print(\"multiple targets\")\n",
    "                multitarget+=1\n",
    "                prots=protid.split(\"|\")\n",
    "                totalcommontargets=len(prots)\n",
    "                #print(\"totalcommontargets\",totalcommontargets)\n",
    "                for pid in prots:\n",
    "                    if pid in dictpid_as.keys():\n",
    "                        #print(\"in---\", pid)\n",
    "                        if seqlength == '':                            \n",
    "                            seqlength=dictpid_sequenceLength[pid]\n",
    "                            seqlengthonly=seqlength.replace('AA','')\n",
    "                            seq=dictpid_as[pid]  \n",
    "                            seqonly=seq.split(':')[1]\n",
    "                            pfam=dictpid_pfam[pid]\n",
    "                            #print(\"in if\", pfam)\n",
    "                            goc=dictpid_goclassifiers[pid] \n",
    "                            subcel=dictpid_subcellularlocation[pid]\n",
    "                            pathway=dictpid_pathway[pid]\n",
    "                        else:\n",
    "                            \n",
    "                            existingseqlength= int(seqlengthonly)\n",
    "                            newseqlength = dictpid_sequenceLength[pid]\n",
    "                            newseqlength=newseqlength.replace('AA','')\n",
    "                            seqlengthonly= existingseqlength + int(newseqlength)\n",
    "                            seq=dictpid_as[pid]  \n",
    "                            newseqonly=seq.split(':')[1]\n",
    "                            seqonly = seqonly + '::'+newseqonly\n",
    "                            newpfam=dictpid_pfam[pid]\n",
    "                            pfam = pfam + ','+newpfam\n",
    "                            #print(\"in else newpfam\", newpfam)\n",
    "                            #print(\"in else pfam\", pfam)\n",
    "                            newgoc=dictpid_goclassifiers[pid] \n",
    "                            goc= goc +'::'+ newgoc\n",
    "                            newsubcel=dictpid_subcellularlocation[pid]\n",
    "                            subcel= subcel + '::'+  newsubcel\n",
    "                            \n",
    "                            newpathway=dictpid_pathway[pid]\n",
    "                            pathway = pathway +  '::'+newpathway\n",
    "                            \n",
    "                \n",
    "                    \n",
    "            else:\n",
    "                totalcommontargets=1\n",
    "                #print(\"single targets\")\n",
    "                singletarget+=1\n",
    "                if protid in dictpid_as.keys():\n",
    "                    ctargetcount=1\n",
    "                    seqlength=dictpid_sequenceLength[protid]\n",
    "                    seqlengthonly=seqlength.replace('AA','')\n",
    "                    seq=dictpid_as[protid]  \n",
    "                    seqonly=seq.split(':')[1]\n",
    "                    pfam=dictpid_pfam[protid]\n",
    "                    #print(\"only one target\", pfam)\n",
    "                    goc=dictpid_goclassifiers[protid] \n",
    "                    subcel=dictpid_subcellularlocation[protid]\n",
    "                    pathway=dictpid_pathway[protid] \n",
    "            \n",
    "            print(\"done count=\",count )\n",
    "        \n",
    "            writer.writerow([trialid, protid, totalcommontargets, seqlengthonly, seqonly, pfam, goc, subcel, pathway ])\n",
    "            #if count == 3:\n",
    "                #break\n",
    "print(\"singletarget=\",singletarget)\n",
    "print(\"multitarget\",multitarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<------------------end-------------------->\n"
     ]
    }
   ],
   "source": [
    "print(\"<------------------end-------------------->\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvclin",
   "language": "python",
   "name": "myenvclin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
